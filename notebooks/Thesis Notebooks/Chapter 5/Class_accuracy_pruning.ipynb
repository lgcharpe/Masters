{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "from __future__ import unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import tqdm\n",
    "from hfunc import models\n",
    "from hfunc import metrics\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-created functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_pruning(model, tester_model, x, y, layer_sizes, tol, ignore_cutoff=-1e-2, method='exhaustive', label=None, frac=0.75):\n",
    "\n",
    "    loss, acc = model.evaluate(x, y, verbose=0, batch_size=256)\n",
    "    original = model.get_weights()\n",
    "    weight_len = len(original) - 3\n",
    "    bas = [acc]\n",
    "    bls = [loss]\n",
    "    best_weights = model.get_weights()\n",
    "    best_acc = 0\n",
    "    best_loss = 1e20\n",
    "    ol = loss\n",
    "    oa = acc\n",
    "    amounts = []\n",
    "    places = []\n",
    "    \n",
    "    if label:\n",
    "        y_pred = model.predict(x)\n",
    "        y_pred_flat = np.argmax(y_pred, axis=1)\n",
    "        y_pred_class = np.array([1 if y == label else 0 for yp in y_pred_flat])\n",
    "        y_class = np.array([1 if yp == label else 0 for yp in y])\n",
    "\n",
    "        oa = (y_pred_class == y_class).mean()\n",
    "\n",
    "    for layer, size in enumerate(layer_sizes):\n",
    "        end_not_reached = True\n",
    "        num_removed = 0\n",
    "        nodes_removed = []\n",
    "        if method == 'exhaustive':\n",
    "            current_pos = 0\n",
    "            best_change = tol\n",
    "            best_pos = -1\n",
    "            improved = False\n",
    "            while end_not_reached or improved:\n",
    "                if not(end_not_reached):\n",
    "                    end_not_reached = True\n",
    "                    improved = False\n",
    "                    current_pos = 0\n",
    "                    size -= 1\n",
    "                    nodes_removed += [best_pos]\n",
    "                    best_weights[weight_len - (2*layer+1)][...,best_pos] = 0\n",
    "                    best_weights[weight_len - 2*layer][best_pos] = 0\n",
    "                    best_pos = -1\n",
    "                    ol = best_loss\n",
    "                    oa = best_acc\n",
    "                    bas += [best_acc]\n",
    "                    bls += [best_loss]\n",
    "                    best_change = tol\n",
    "                    num_removed += 1\n",
    "                if current_pos in nodes_removed:\n",
    "                    current_pos += 1\n",
    "                    if current_pos - num_removed >= size:\n",
    "                        end_not_reached = False\n",
    "                    continue\n",
    "                w = copy.deepcopy(best_weights)\n",
    "                w[weight_len - (2*layer+1)][...,current_pos] = 0\n",
    "                w[weight_len - 2*layer][current_pos] = 0\n",
    "                tester_model.set_weights(w)\n",
    "                nl, na = tester_model.evaluate(x, y, verbose=0, batch_size=256)\n",
    "                if label:\n",
    "                    y_pred = tester_model2.predict(x)\n",
    "                    y_pred_flat = np.argmax(y_pred, axis=1)\n",
    "                    y_pred_class = np.array([1 if yp == label else 0 for yp in y_pred_flat])\n",
    "                    na = (y_pred_class == y_class).mean()\n",
    "                    change = frac*(na - oa) + (1-frac)*(ol - nl) \n",
    "                else:\n",
    "                    change = ol - nl\n",
    "                if change >= best_change:\n",
    "                    best_change = change\n",
    "                    best_pos = current_pos\n",
    "                    improved = True\n",
    "                    best_acc = na\n",
    "                    best_loss = nl\n",
    "                current_pos += 1\n",
    "                if current_pos - num_removed >= size:\n",
    "                    end_not_reached = False\n",
    "        elif method == 'greedy':\n",
    "            nodes_to_estimate = list(np.arange(size))\n",
    "            current_pos = nodes_to_estimate[0]\n",
    "            idx = 0\n",
    "            while end_not_reached:\n",
    "                w = copy.deepcopy(best_weights)\n",
    "                w[weight_len - (2*layer+1)][...,current_pos] = 0\n",
    "                w[weight_len - 2*layer][current_pos] = 0\n",
    "                tester_model.set_weights(w)\n",
    "                nl, na = tester_model.evaluate(x, y, verbose=0, batch_size=256)\n",
    "                \n",
    "                if label:\n",
    "                    y_pred = tester_model2.predict(x)\n",
    "                    y_pred_flat = np.argmax(y_pred, axis=1)\n",
    "                    y_pred_class = np.array([1 if yp == label else 0 for yp in y_pred_flat])\n",
    "                    na = (y_pred_class == y_class).mean()\n",
    "                    change = frac*(na - oa) + (1-frac)*(ol - nl) \n",
    "                else:\n",
    "                    change = ol - nl\n",
    "                    \n",
    "                if change >= tol:\n",
    "                    oa = na\n",
    "                    ol = nl\n",
    "                    size -= 1\n",
    "                    nodes_removed += [current_pos]\n",
    "                    nodes_to_estimate.remove(current_pos)\n",
    "                    best_weights[weight_len - (2*layer+1)][..., current_pos] = 0\n",
    "                    best_weights[weight_len - 2*layer][current_pos] = 0\n",
    "                    bas += [oa]\n",
    "                    bls += [ol]\n",
    "                    num_removed += 1\n",
    "                    idx = 0\n",
    "                elif ol - nl <= ignore_cutoff:\n",
    "                    size -= 1\n",
    "                    nodes_to_estimate.remove(current_pos)\n",
    "                else:\n",
    "                    idx += 1\n",
    "                if idx >= size:\n",
    "                    end_not_reached = False\n",
    "                else:\n",
    "                    current_pos = nodes_to_estimate[idx]\n",
    "        amounts.append(num_removed)\n",
    "        places.append(nodes_removed)\n",
    "\n",
    "    return best_weights, bas, bls, amounts, places"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar = tf.keras.datasets.cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Converting interger values to floats (0 to 1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, train_size=0.85, stratify=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "tester_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "or_loss, or_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "tol = -1e-5\n",
    "ig_cut = -1e-3\n",
    "layer_sizes = [64, 356, 128, 64, 32]\n",
    "K = 10\n",
    "\n",
    "best_weigths, _, _, am_loss_prune, pl_loss_prune = node_pruning(model, tester_model, x_val, y_val, layer_sizes, tol, ig_cut, method='greedy')\n",
    "tester_model.set_weights(best_weights)\n",
    "\n",
    "loss_pruned_loss, loss_pruned_acc = tester_model.evaluate(x_test)\n",
    "\n",
    "y_pred = tester_model.predict(x_test)\n",
    "loss_pruned_class_acc = []\n",
    "yp = np.argmax(y_pred, axis=1)\n",
    "for i in range(K):\n",
    "    a = np.mean((yp[y_test == i] == y_test[y_test == i]))\n",
    "    loss_pruned_class_acc.append(a)\n",
    "\n",
    "    \n",
    "class_pruned_accs = np.zeros(K)\n",
    "class_pruned_losses = np.zeros(K)\n",
    "class_pruned_class_acc = np.zeros((K,K))\n",
    "class_pruned_place = []\n",
    "class_pruned_amounts = []\n",
    "\n",
    "for k in range(K):\n",
    "    best_weigths, _, _, tmp_am, tmp_pl = node_pruning(model, tester_model, x_val, y_val, layer_sizes, tol, ig_cut, method='greedy', layer=k, frac=1)\n",
    "    \n",
    "    class_pruned_amounts += [tmp_am]\n",
    "    class_pruned_places += [tmp_pl]\n",
    "    \n",
    "    tester_model.set_weights(best_weights)\n",
    "\n",
    "    class_pruned_losses[k], class_pruned_accs[k] = tester_model.evaluate(x_test)\n",
    "\n",
    "    y_pred = tester_model.predict(x_test)\n",
    "    yp = np.argmax(y_pred, axis=1)\n",
    "    for i in range(K):\n",
    "        a = np.mean((yp[y_test == i] == y_test[y_test == i]))\n",
    "        class_pruned_class_acc[k,i] = a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
