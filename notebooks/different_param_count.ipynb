{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "from __future__ import unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import copy\n",
    "import tqdm\n",
    "import IProgress\n",
    "from hfunc import models\n",
    "from hfunc import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "class_accuracy = metrics.ClassAccuracy()\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Converting interger values to floats (0 to 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = tf.keras.datasets.cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "y_train, y_test = y_train.flatten(), y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(32, 32, 3)),\n",
    "        tf.keras.layers.Dense(size, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "#model2.fit(x_train, y_train, epochs=100, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.5487 - accuracy: 0.8127\n",
      "Epoch 2/5\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.8416\n",
      "Epoch 3/5\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.8500\n",
      "Epoch 4/5\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.8576\n",
      "Epoch 5/5\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.3904 - accuracy: 0.8639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22a12a6bf88>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train, y_train, epochs=5, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.1609 - accuracy: 0.9402\n",
      "Epoch 2/5\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1578 - accuracy: 0.9408\n",
      "Epoch 3/5\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.1541 - accuracy: 0.9426\n",
      "Epoch 4/5\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.1514 - accuracy: 0.9437\n",
      "Epoch 5/5\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1476 - accuracy: 0.9455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x228ad408ec8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train, y_train, epochs=5, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2197 - accuracy: 0.9174\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1923 - accuracy: 0.9264\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1866 - accuracy: 0.9294\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1770 - accuracy: 0.9331\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1736 - accuracy: 0.9339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x228a60a8708>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train, y_train, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester_model2 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(32, 32, 3)),\n",
    "        tf.keras.layers.Dense(size, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "tester_model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 - 0s - loss: 2.6039 - accuracy: 0.0998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.6038713455200195, 0.0997999981045723]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(x_test, y_test, verbose=2, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 - 0s - loss: 2.6039 - accuracy: 0.0998\n",
      "Node 0: 0.00010000169277191162\n",
      "Node 1: 0.0\n",
      "Node 2: -0.00010000169277191162\n",
      "Node 3: 0.00010000169277191162\n",
      "Node 4: 0.00020000338554382324\n",
      "Node 5: -0.00019999593496322632\n",
      "Node 6: 0.0\n",
      "Node 7: 0.00010000169277191162\n",
      "Node 8: 0.0\n",
      "Node 9: 0.0\n",
      "Node 10: -0.00010000169277191162\n",
      "Node 11: 0.00010000169277191162\n",
      "Node 12: 0.0\n",
      "Node 13: -0.00010000169277191162\n",
      "Node 14: -0.00019999593496322632\n",
      "Node 15: -0.00010000169277191162\n",
      "Node 16: 0.0\n",
      "Node 17: 0.0\n",
      "Node 18: -0.0005999952554702759\n",
      "Node 19: -0.00010000169277191162\n",
      "Node 20: 0.0\n",
      "Node 21: -0.00029999762773513794\n",
      "Node 22: -0.00010000169277191162\n",
      "Node 23: -0.0018999949097633362\n",
      "Node 24: -0.00029999762773513794\n",
      "Node 25: -0.0014999955892562866\n",
      "Node 26: 0.0\n",
      "Node 27: 0.00020000338554382324\n",
      "Node 28: 0.0\n",
      "Node 29: 0.0\n",
      "Node 30: -0.00010000169277191162\n",
      "Node 31: -0.00010000169277191162\n",
      "Node 32: -0.00019999593496322632\n",
      "Node 33: 0.0\n",
      "Node 34: 0.00010000169277191162\n",
      "Node 35: -0.0006999969482421875\n",
      "Node 36: 0.0\n",
      "Node 37: 0.0\n",
      "Node 38: -0.00010000169277191162\n",
      "Node 39: -0.00010000169277191162\n",
      "Node 40: 0.0\n",
      "Node 41: 0.0\n",
      "Node 42: 0.0\n",
      "Node 43: -0.00019999593496322632\n",
      "Node 44: 0.0\n",
      "Node 45: -0.00010000169277191162\n",
      "Node 46: -0.00299999862909317\n",
      "Node 47: -0.00019999593496322632\n",
      "Node 48: -0.00010000169277191162\n",
      "Node 49: -0.0007999986410140991\n",
      "Node 50: -0.00019999593496322632\n",
      "Node 51: 0.0\n",
      "Node 52: 0.00010000169277191162\n",
      "Node 53: 0.0\n",
      "Node 54: -0.0005000010132789612\n",
      "Node 55: -0.0007999986410140991\n",
      "Node 56: -0.00019999593496322632\n",
      "Node 57: 0.0\n",
      "Node 58: 0.0\n",
      "Node 59: 0.0\n",
      "Node 60: 0.00010000169277191162\n",
      "Node 61: 0.00020000338554382324\n",
      "Node 62: -0.00010000169277191162\n",
      "Node 63: -0.00029999762773513794\n",
      "Node 64: -0.00010000169277191162\n",
      "Node 65: 0.0\n",
      "Node 66: -0.0007999986410140991\n",
      "Node 67: -0.00010000169277191162\n",
      "Node 68: -0.00010000169277191162\n",
      "Node 69: 0.00010000169277191162\n",
      "Node 70: 0.00010000169277191162\n",
      "Node 71: 0.0\n",
      "Node 72: -0.00029999762773513794\n",
      "Node 73: -0.00029999762773513794\n",
      "Node 74: -0.0031999945640563965\n",
      "Node 75: 0.0\n",
      "Node 76: 0.0\n",
      "Node 77: -0.00010000169277191162\n",
      "Node 78: 0.0\n",
      "Node 79: 0.0\n",
      "Node 80: 0.0\n",
      "Node 81: 0.0\n",
      "Node 82: 0.0\n",
      "Node 83: 0.00030000507831573486\n",
      "Node 84: -0.00010000169277191162\n",
      "Node 85: 0.0\n",
      "Node 86: 0.0\n",
      "Node 87: 0.00010000169277191162\n",
      "Node 88: 0.0\n",
      "Node 89: 0.00030000507831573486\n",
      "Node 90: -0.0011999979615211487\n",
      "Node 91: -0.00010000169277191162\n",
      "Node 92: 0.0\n",
      "Node 93: 0.0\n",
      "Node 94: 0.00010000169277191162\n",
      "Node 95: -0.00019999593496322632\n",
      "Node 96: 0.0\n",
      "Node 97: 0.00020000338554382324\n",
      "Node 98: 0.0\n",
      "Node 99: -0.002499997615814209\n",
      "Node 100: -0.00019999593496322632\n",
      "Node 101: 0.0\n",
      "Node 102: 0.0\n",
      "Node 103: 0.00020000338554382324\n",
      "Node 104: -0.00010000169277191162\n",
      "Node 105: 0.0\n",
      "Node 106: 0.00010000169277191162\n",
      "Node 107: 0.00010000169277191162\n",
      "Node 108: -0.00010000169277191162\n",
      "Node 109: 0.0\n",
      "Node 110: 0.0006000027060508728\n",
      "Node 111: 0.0\n",
      "Node 112: 0.0\n",
      "Node 113: -0.00010000169277191162\n",
      "Node 114: 0.00020000338554382324\n",
      "Node 115: -0.00019999593496322632\n",
      "Node 116: 0.00020000338554382324\n",
      "Node 117: 0.00020000338554382324\n",
      "Node 118: 0.0\n",
      "Node 119: 0.00010000169277191162\n",
      "Node 120: -0.00010000169277191162\n",
      "Node 121: 0.00030000507831573486\n",
      "Node 122: 0.0\n",
      "Node 123: -0.00010000169277191162\n",
      "Node 124: 0.0\n",
      "Node 125: -0.00039999932050704956\n",
      "Node 126: 0.0\n",
      "Node 127: 0.00010000169277191162\n"
     ]
    }
   ],
   "source": [
    "l, a = model2.evaluate(x_test, y_test, verbose=2, batch_size=256)\n",
    "or_weights = model2.get_weights()\n",
    "tol_low = -1e-5\n",
    "tol_high = 1e-5\n",
    "num_zeros, num_worse, num_important = (0, 0, 0)\n",
    "z = []\n",
    "wr = []\n",
    "imp = []\n",
    "for i in range(size):\n",
    "    w = copy.deepcopy(or_weights)\n",
    "    w[0][:,i] = 0\n",
    "    w[1][i] = 0\n",
    "    w[2][i,:] = 0\n",
    "    tester_model2.set_weights(w)\n",
    "    nl, na = tester_model2.evaluate(x_test, y_test, verbose=0, batch_size=256)\n",
    "    print(f\"Node {i}:\", 1.*(na - a) + 0*(l - nl))\n",
    "    change = l - nl\n",
    "    if change <= tol_high and change >= tol_low:\n",
    "        num_zeros += 1\n",
    "        z += [i]\n",
    "    elif change > 0:\n",
    "        num_worse += 1\n",
    "        wr += [i]\n",
    "    else:\n",
    "        num_important += 1\n",
    "        imp += [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero Nodes: 12\n",
      "Worse Nodes: 69\n",
      "Important Nodes: 47\n"
     ]
    }
   ],
   "source": [
    "print(\"Zero Nodes:\", num_zeros)\n",
    "print(\"Worse Nodes:\", num_worse)\n",
    "print(\"Important Nodes:\", num_important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## IMPORTANT NODES ########\n",
      "Node 0: -0.011357992887496948\n",
      "Node 1: -0.0003668367862701416\n",
      "Node 2: -0.01113802194595337\n",
      "Node 3: -0.004285454750061035\n",
      "Node 4: -0.006938248872756958\n",
      "Node 7: -0.009644269943237305\n",
      "Node 8: -0.004353582859039307\n",
      "Node 9: -0.011253029108047485\n",
      "Node 10: -0.005652725696563721\n",
      "Node 11: -0.005932420492172241\n",
      "Node 12: -0.012002736330032349\n",
      "Node 13: -0.003979533910751343\n",
      "Node 14: -0.002023845911026001\n",
      "Node 18: -0.0007498264312744141\n",
      "Node 20: -0.013696044683456421\n",
      "Node 21: -0.003553926944732666\n",
      "Node 22: -0.02637985348701477\n",
      "Node 23: -0.0009359419345855713\n",
      "Node 26: -0.0028370916843414307\n",
      "Node 27: -0.0482616126537323\n",
      "Node 28: -0.007632553577423096\n",
      "Node 29: -0.005993574857711792\n",
      "Node 32: -0.00876551866531372\n",
      "Node 33: -0.009699732065200806\n",
      "Node 34: -0.002858489751815796\n",
      "Node 35: -0.03807932138442993\n",
      "Node 36: -0.007287859916687012\n",
      "Node 37: -0.005283772945404053\n",
      "Node 38: -0.029007047414779663\n",
      "Node 39: -0.022837698459625244\n",
      "Node 40: -0.006233334541320801\n",
      "Node 43: -0.004154711961746216\n",
      "Node 44: -0.003835707902908325\n",
      "Node 45: -0.02932301163673401\n",
      "Node 46: -0.001864016056060791\n",
      "Node 47: -0.01565578579902649\n",
      "Node 48: -0.0024992823600769043\n",
      "Node 49: -0.004851490259170532\n",
      "Node 50: -0.008555114269256592\n",
      "Node 52: -0.010775238275527954\n",
      "Node 53: -0.024910300970077515\n",
      "Node 54: -0.001383453607559204\n",
      "Node 56: -0.0019832253456115723\n",
      "Node 57: -0.006586700677871704\n",
      "Node 60: -0.006947845220565796\n",
      "Node 61: -0.016944795846939087\n",
      "Node 62: -0.0024840831756591797\n",
      "Node 63: -0.0016354918479919434\n",
      "Node 66: -0.005114614963531494\n",
      "Node 67: -0.009639054536819458\n",
      "Node 69: -0.011879384517669678\n",
      "Node 70: -0.017743408679962158\n",
      "Node 71: -0.001133352518081665\n",
      "Node 72: -0.006983548402786255\n",
      "Node 73: -0.007431119680404663\n",
      "Node 74: -0.011303842067718506\n",
      "Node 75: -0.010018527507781982\n",
      "Node 77: -0.001469641923904419\n",
      "Node 78: -0.002987295389175415\n",
      "Node 80: -0.008313417434692383\n",
      "Node 81: -0.0028142035007476807\n",
      "Node 82: -0.0023891031742095947\n",
      "Node 85: -0.008776813745498657\n",
      "Node 87: -0.011393636465072632\n",
      "Node 88: -0.012771248817443848\n",
      "Node 89: -0.00534898042678833\n",
      "Node 90: -0.0027963221073150635\n",
      "Node 92: -0.0009834766387939453\n",
      "Node 93: -0.01785975694656372\n",
      "Node 97: -0.009975194931030273\n",
      "Node 99: -0.007930576801300049\n",
      "Node 100: -0.0008494257926940918\n",
      "Node 101: -0.0025306642055511475\n",
      "Node 103: -0.00478401780128479\n",
      "Node 104: -0.0050806403160095215\n",
      "Node 107: -0.007266223430633545\n",
      "Node 108: -0.0049498677253723145\n",
      "Node 109: -0.004711329936981201\n",
      "Node 110: -0.001723647117614746\n",
      "Node 111: -0.004935145378112793\n",
      "Node 113: -0.0011411309242248535\n",
      "Node 114: -0.0003304779529571533\n",
      "Node 115: -0.0064469873905181885\n",
      "Node 116: -0.019040793180465698\n",
      "Node 118: -0.012627780437469482\n",
      "Node 119: -0.018404483795166016\n",
      "Node 122: -0.001327604055404663\n",
      "Node 123: -0.0034981369972229004\n",
      "Node 124: -0.010604143142700195\n"
     ]
    }
   ],
   "source": [
    "print(\"######## IMPORTANT NODES ########\")\n",
    "for i in imp:\n",
    "    w = copy.deepcopy(or_weights)\n",
    "    w[0][:,i] = 0\n",
    "    w[1][i] = 0\n",
    "    w[2][i,:] = 0\n",
    "    tester_model2.set_weights(w)\n",
    "    nl, na = tester_model2.evaluate(x_test, y_test, verbose=0)\n",
    "    print(f\"Node {i}:\", 0.*(na - a) + 1.0*(l - nl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## WORSE NODES ########\n",
      "Node 5: 0.006364375352859497\n",
      "Node 6: 0.005842745304107666\n",
      "Node 15: 0.0006026327610015869\n",
      "Node 16: 0.0008873343467712402\n",
      "Node 17: 0.0024060606956481934\n",
      "Node 19: 0.0041099488735198975\n",
      "Node 25: 0.000403672456741333\n",
      "Node 30: 0.003470808267593384\n",
      "Node 51: 0.0010623335838317871\n",
      "Node 55: 0.003407120704650879\n",
      "Node 58: 0.0009611845016479492\n",
      "Node 64: 0.0014757513999938965\n",
      "Node 65: 0.00016021728515625\n",
      "Node 68: 5.054473876953125e-05\n",
      "Node 79: 0.0002141892910003662\n",
      "Node 83: 0.008299171924591064\n",
      "Node 84: 0.0002543032169342041\n",
      "Node 86: 0.0018314719200134277\n",
      "Node 91: 0.00015357136726379395\n",
      "Node 94: 0.0015983879566192627\n",
      "Node 102: 0.005549639463424683\n",
      "Node 105: 0.005634099245071411\n",
      "Node 106: 0.0014474093914031982\n",
      "Node 112: 0.0030728578567504883\n",
      "Node 117: 0.0007586181163787842\n",
      "Node 120: 0.000581204891204834\n",
      "Node 121: 0.0006135106086730957\n",
      "Node 125: 0.0022307932376861572\n",
      "Node 126: 0.000684201717376709\n",
      "Node 127: 0.000967562198638916\n",
      "0.06509572267532349\n",
      "0.0021698574225107827\n"
     ]
    }
   ],
   "source": [
    "print(\"######## WORSE NODES ########\")\n",
    "tot = 0\n",
    "for i in wr:\n",
    "    w = copy.deepcopy(or_weights)\n",
    "    w[0][:,i] = 0\n",
    "    w[1][i] = 0\n",
    "    w[2][i,:] = 0\n",
    "    tester_model2.set_weights(w)\n",
    "    nl, na = tester_model2.evaluate(x_test, y_test, verbose=0)\n",
    "    print(f\"Node {i}:\", 0.*(na - a) + 1.0*(l - nl))\n",
    "    tot += (l - nl)\n",
    "print(tot)\n",
    "print(tot / num_worse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 - 0s - loss: 2.6008 - accuracy: 0.0989\n",
      "0.006856966018676757\n",
      "Found something better\n",
      "0.015709051489830015\n",
      "Found something better\n",
      "0.030262802541255948\n",
      "Found something better\n",
      "0.044894503057003016\n",
      "Found something better\n",
      "0.046278446912765496\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.09638000279664993 --- Loss: 2.5336530208587646 --- Change: 0.046278446912765496 --- New tol: -1e-05\n",
      "0.005933973938226699\n",
      "Found something better\n",
      "0.011274542659521103\n",
      "Found something better\n",
      "0.020122868567705152\n",
      "Found something better\n",
      "0.03969955369830132\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.09625999629497528 --- Loss: 2.4768879413604736 --- Change: 0.03969955369830132 --- New tol: -1e-05\n",
      "0.004554710537195206\n",
      "Found something better\n",
      "0.009817975014448165\n",
      "Found something better\n",
      "0.017311021685600277\n",
      "Found something better\n",
      "0.022616217285394667\n",
      "Found something better\n",
      "0.0349423386156559\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.10294000059366226 --- Loss: 2.429833173751831 --- Change: 0.0349423386156559 --- New tol: -1e-05\n",
      "0.0012651018798351286\n",
      "Found something better\n",
      "0.006316636502742766\n",
      "Found something better\n",
      "0.00880240947008133\n",
      "Found something better\n",
      "0.02529735043644905\n",
      "Found something better\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 586. MiB for an array with shape (50000, 32, 32, 3) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-442f96555951>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_pos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mtester_model2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mnl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtester_model2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mna\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0moa\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.7\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mol\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnl\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbest_change\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mbest_change\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mna\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0moa\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.7\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mol\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1055\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1057\u001b[1;33m           model=self)\n\u001b[0m\u001b[0;32m   1058\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m       \u001b[1;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[0;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1112\u001b[1;33m         model=model)\n\u001b[0m\u001b[0;32m   1113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m                **kwargs):\n\u001b[0;32m    264\u001b[0m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[0;32m    267\u001b[0m         sample_weights, sample_weight_modes)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[1;34m(inputs)\u001b[0m\n\u001b[0;32m   1011\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m   \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1014\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_list_to_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 617\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 617\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1006\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1007\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1008\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1009\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mscipy_sparse\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mscipy_sparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1010\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1340\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1341\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[1;31m# Unused.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    260\u001b[0m   \"\"\"\n\u001b[0;32m    261\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[1;32m--> 262\u001b[1;33m                         allow_broadcast=True)\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    268\u001b[0m   \u001b[0mctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 586. MiB for an array with shape (50000, 32, 32, 3) and data type float32"
     ]
    }
   ],
   "source": [
    "loss, acc = model2.evaluate(x_train, y_train, verbose=2, batch_size=512)\n",
    "end_not_reached = True\n",
    "improved = False\n",
    "tol = -1e-5\n",
    "current_pos = 0\n",
    "best_pos = -1\n",
    "best_change = tol\n",
    "original2 = model2.get_weights()\n",
    "bas2 = [acc]\n",
    "bls2 = [loss]\n",
    "best_weights2 = model2.get_weights()\n",
    "nodes_removed2 = []\n",
    "best_acc = 0\n",
    "best_loss = 1e20\n",
    "ol = loss\n",
    "oa = acc\n",
    "num_removed2 = 0\n",
    "while end_not_reached or improved:\n",
    "    if not(end_not_reached):\n",
    "        end_not_reached = True\n",
    "        improved = False\n",
    "        current_pos = 0\n",
    "        size -= 1\n",
    "        nodes_removed2 += [best_pos]\n",
    "        best_weights2[0][:,best_pos] = 0\n",
    "        best_weights2[1][best_pos] = 0\n",
    "        best_weights2[2][best_pos,:] = 0\n",
    "        best_pos = -1\n",
    "        #tol -= best_change\n",
    "        ol = best_loss\n",
    "        oa = best_acc\n",
    "        bas2 += [best_acc]\n",
    "        bls2 += [best_loss]\n",
    "        print(\"Improvement has occured!! Accuracy:\", best_acc, \"--- Loss:\", best_loss, '--- Change:', best_change, '--- New tol:', tol)\n",
    "        best_change = tol\n",
    "        num_removed2 += 1\n",
    "    if current_pos in nodes_removed2:\n",
    "        current_pos += 1\n",
    "        if current_pos - num_removed2 >= size:\n",
    "            end_not_reached = False\n",
    "        continue\n",
    "    w = copy.deepcopy(best_weights2)\n",
    "    w[0][:,current_pos] = 0\n",
    "    w[1][current_pos] = 0\n",
    "    w[2][current_pos,:] = 0\n",
    "    tester_model2.set_weights(w)\n",
    "    nl, na = tester_model2.evaluate(x_train, y_train, verbose=0, batch_size=1024)\n",
    "    if 0.3*(na - oa) + 0.7*(ol - nl) > best_change:\n",
    "        best_change = 0.3*(na - oa) + 0.7*(ol - nl)\n",
    "        print(best_change)\n",
    "        best_pos = current_pos\n",
    "        improved = True\n",
    "        best_acc = na\n",
    "        best_loss = nl\n",
    "        print(\"Found something better\")\n",
    "    current_pos += 1\n",
    "    if current_pos - num_removed2 >= size:\n",
    "        end_not_reached = False\n",
    "    if current_pos%200 == 0:\n",
    "        print(\"Did 200 iterations\")\n",
    "\n",
    "tester_model2.set_weights(best_weights2)\n",
    "loss2, acc2 = tester_model2.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_removed2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model2.predict(x_test)\n",
    "\n",
    "K = len(set(y_test))\n",
    "yp = tf.argmax(y_pred, axis=1)\n",
    "acc = []\n",
    "for i in range(K):\n",
    "    a = np.mean((yp[y_test == i] == y_test[y_test == i]).numpy())\n",
    "    acc.append(a)\n",
    "print(acc)\n",
    "\n",
    "m = tf.keras.metrics.AUC()\n",
    "m.update_state(tf.one_hot(y_test, 10), y_pred)\n",
    "print(m.result())\n",
    "AUC_or = m.result().numpy()\n",
    "acc_or = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tester_model2.predict(x_test)\n",
    "\n",
    "K = len(set(y_test))\n",
    "yp = tf.argmax(y_pred, axis=1)\n",
    "acc = []\n",
    "for i in range(K):\n",
    "    a = np.mean((yp[y_test == i] == y_test[y_test == i]).numpy())\n",
    "    acc.append(a)\n",
    "print(acc)\n",
    "\n",
    "m = tf.keras.metrics.AUC()\n",
    "m.update_state(tf.one_hot(y_test, 10), y_pred)\n",
    "print(m.result())\n",
    "AUC_red = m.result().numpy()\n",
    "acc_red = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((np.array(acc_red) - np.array(acc_or)))\n",
    "print(AUC_red - AUC_or)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weights = [np.zeros((best_weights[0].shape[0], best_weights[0].shape[1] - num_removed)), np.zeros((best_weights[1].shape[0] - num_removed)), np.zeros((best_weights[2].shape[0] - num_removed, best_weights[2].shape[1])), best_weights[3]]\n",
    "\n",
    "j = 0\n",
    "for i in range(len(best_weights[1])):\n",
    "    if i not in nodes_removed:\n",
    "        new_weights[0][:, j] = best_weights[0][:, i]\n",
    "        new_weights[1][j] = best_weights[1][i]\n",
    "        new_weights[2][j, :] = best_weights[2][i, :]\n",
    "        j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128-num_removed, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "red_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "red_model.set_weights(new_weights)\n",
    "red_model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 - 0s - loss: 0.3335 - accuracy: 0.8889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1024 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.855, 0.968, 0.861, 0.927, 0.738, 0.973, 0.677, 0.952, 0.969, 0.969]\n",
      "tf.Tensor(0.9906246, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1024/1024 [01:31<00:00, 11.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.5710 - accuracy: 0.7640\n",
      "[0.549, 0.99, 0.041, 0.639, 0.9, 0.943, 0.84, 0.974, 0.974, 0.79]\n",
      "tf.Tensor(0.980825, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "l, a = model2.evaluate(x_test, y_test, verbose=2, batch_size=256)\n",
    "\n",
    "y_pred = model2.predict(x_test)\n",
    "\n",
    "K = len(set(y_test))\n",
    "yp = tf.argmax(y_pred, axis=1)\n",
    "acc = []\n",
    "for i in range(K):\n",
    "    a = np.mean((yp[y_test == i] == y_test[y_test == i]).numpy())\n",
    "    acc.append(a)\n",
    "print(acc)\n",
    "\n",
    "m = tf.keras.metrics.AUC()\n",
    "m.update_state(tf.one_hot(y_test, 10), y_pred)\n",
    "print(m.result())\n",
    "\n",
    "or_weights = model2.get_weights()\n",
    "tol_low = -1e-5\n",
    "tol_high = 1e-5\n",
    "num_zeros, num_worse, num_important = (0, 0, 0)\n",
    "z = []\n",
    "wr = []\n",
    "imp = []\n",
    "best_weights2 = model2.get_weights()\n",
    "\n",
    "for i in tqdm.trange(size):\n",
    "    w = copy.deepcopy(or_weights)\n",
    "    w[0][:,i] = 0\n",
    "    w[1][i] = 0\n",
    "    w[2][i,:] = 0\n",
    "    tester_model2.set_weights(w)\n",
    "    nl, na = tester_model2.evaluate(x_test, y_test, verbose=0, batch_size=256)\n",
    "    # print(f\"Node {i}:\", 1.*(na - a) + 0*(l - nl))\n",
    "    change = l - nl\n",
    "    if change <= tol_high and change >= tol_low:\n",
    "        num_zeros += 1\n",
    "        z += [i]\n",
    "        best_weights2[0][:,i] = 0\n",
    "        best_weights2[1][i] = 0\n",
    "        best_weights2[2][i,:] = 0\n",
    "    elif change > 0:\n",
    "        num_worse += 1\n",
    "        wr += [i]\n",
    "        best_weights2[0][:,i] = 0\n",
    "        best_weights2[1][i] = 0\n",
    "        best_weights2[2][i,:] = 0\n",
    "    else:\n",
    "        num_important += 1\n",
    "        imp += [i]\n",
    "\n",
    "tester_model2.set_weights(best_weights2)\n",
    "loss2, acc2 = tester_model2.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "y_pred = tester_model2.predict(x_test)\n",
    "\n",
    "K = len(set(y_test))\n",
    "yp = tf.argmax(y_pred, axis=1)\n",
    "acc = []\n",
    "for i in range(K):\n",
    "    a = np.mean((yp[y_test == i] == y_test[y_test == i]).numpy())\n",
    "    acc.append(a)\n",
    "print(acc)\n",
    "\n",
    "m = tf.keras.metrics.AUC()\n",
    "m.update_state(tf.one_hot(y_test, 10), y_pred)\n",
    "print(m.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 - 0s - loss: 0.2042 - accuracy: 0.9226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1024 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.855, 0.968, 0.861, 0.927, 0.738, 0.973, 0.677, 0.952, 0.969, 0.969]\n",
      "tf.Tensor(0.9906246, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1024/1024 [03:58<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.4497 - accuracy: 0.8302\n",
      "[0.645, 0.985, 0.572, 0.682, 0.857, 0.893, 0.846, 0.984, 0.971, 0.867]\n",
      "tf.Tensor(0.9865412, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "l, a = model2.evaluate(x_train, y_train, verbose=2, batch_size=256)\n",
    "\n",
    "y_pred = model2.predict(x_test)\n",
    "\n",
    "K = len(set(y_test))\n",
    "yp = tf.argmax(y_pred, axis=1)\n",
    "acc = []\n",
    "for i in range(K):\n",
    "    a = np.mean((yp[y_test == i] == y_test[y_test == i]).numpy())\n",
    "    acc.append(a)\n",
    "print(acc)\n",
    "\n",
    "m = tf.keras.metrics.AUC()\n",
    "m.update_state(tf.one_hot(y_test, 10), y_pred)\n",
    "print(m.result())\n",
    "\n",
    "or_weights = model2.get_weights()\n",
    "tol_low = -1e-5\n",
    "tol_high = 1e-5\n",
    "num_zeros, num_worse, num_important = (0, 0, 0)\n",
    "z = []\n",
    "wr = []\n",
    "imp = []\n",
    "best_weights2 = model2.get_weights()\n",
    "\n",
    "for i in tqdm.trange(size):\n",
    "    w = copy.deepcopy(or_weights)\n",
    "    w[0][:,i] = 0\n",
    "    w[1][i] = 0\n",
    "    w[2][i,:] = 0\n",
    "    tester_model2.set_weights(w)\n",
    "    nl, na = tester_model2.evaluate(x_train, y_train, verbose=0, batch_size=x_train.shape[0])\n",
    "    # print(f\"Node {i}:\", 1.*(na - a) + 0*(l - nl))\n",
    "    change = l - nl\n",
    "    if change <= tol_high and change >= tol_low:\n",
    "        num_zeros += 1\n",
    "        z += [i]\n",
    "        best_weights2[0][:,i] = 0\n",
    "        best_weights2[1][i] = 0\n",
    "        best_weights2[2][i,:] = 0\n",
    "    elif change > 0:\n",
    "        num_worse += 1\n",
    "        wr += [i]\n",
    "        best_weights2[0][:,i] = 0\n",
    "        best_weights2[1][i] = 0\n",
    "        best_weights2[2][i,:] = 0\n",
    "    else:\n",
    "        num_important += 1\n",
    "        imp += [i]\n",
    "\n",
    "tester_model2.set_weights(best_weights2)\n",
    "loss2, acc2 = tester_model2.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "y_pred = tester_model2.predict(x_test)\n",
    "\n",
    "K = len(set(y_test))\n",
    "yp = tf.argmax(y_pred, axis=1)\n",
    "acc = []\n",
    "for i in range(K):\n",
    "    a = np.mean((yp[y_test == i] == y_test[y_test == i]).numpy())\n",
    "    acc.append(a)\n",
    "print(acc)\n",
    "\n",
    "m = tf.keras.metrics.AUC()\n",
    "m.update_state(tf.one_hot(y_test, 10), y_pred)\n",
    "print(m.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1024 0\n"
     ]
    }
   ],
   "source": [
    "print(num_zeros, num_worse, num_important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 - 0s - loss: 0.3335 - accuracy: 0.8889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                | 2/1024 [00:00<01:29, 11.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.855, 0.968, 0.861, 0.927, 0.738, 0.973, 0.677, 0.952, 0.969, 0.969]\n",
      "tf.Tensor(0.9906246, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1024/1024 [01:28<00:00, 11.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.5746 - accuracy: 0.7623\n",
      "[0.534, 0.991, 0.045, 0.623, 0.885, 0.95, 0.858, 0.972, 0.979, 0.786]\n",
      "tf.Tensor(0.98067045, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "l, a = model2.evaluate(x_test, y_test, verbose=2, batch_size=256)\n",
    "\n",
    "y_pred = model2.predict(x_test)\n",
    "\n",
    "K = len(set(y_test))\n",
    "yp = tf.argmax(y_pred, axis=1)\n",
    "acc = []\n",
    "for i in range(K):\n",
    "    a = np.mean((yp[y_test == i] == y_test[y_test == i]).numpy())\n",
    "    acc.append(a)\n",
    "print(acc)\n",
    "\n",
    "m = tf.keras.metrics.AUC()\n",
    "m.update_state(tf.one_hot(y_test, 10), y_pred)\n",
    "print(m.result())\n",
    "\n",
    "or_weights = model2.get_weights()\n",
    "tol_low = 0\n",
    "tol_high = 0\n",
    "num_zeros, num_worse, num_important = (0, 0, 0)\n",
    "z = []\n",
    "wr = []\n",
    "imp = []\n",
    "best_weights2 = model2.get_weights()\n",
    "\n",
    "for i in tqdm.trange(size):\n",
    "    w = copy.deepcopy(or_weights)\n",
    "    w[0][:,i] = 0\n",
    "    w[1][i] = 0\n",
    "    w[2][i,:] = 0\n",
    "    tester_model2.set_weights(w)\n",
    "    nl, na = tester_model2.evaluate(x_test, y_test, verbose=0, batch_size=256)\n",
    "    # print(f\"Node {i}:\", 1.*(na - a) + 0*(l - nl))\n",
    "    change = l - nl\n",
    "    if change <= tol_high and change >= tol_low:\n",
    "        num_zeros += 1\n",
    "        z += [i]\n",
    "        best_weights2[0][:,i] = 0\n",
    "        best_weights2[1][i] = 0\n",
    "        best_weights2[2][i,:] = 0\n",
    "    elif change > 0:\n",
    "        num_worse += 1\n",
    "        wr += [i]\n",
    "        best_weights2[0][:,i] = 0\n",
    "        best_weights2[1][i] = 0\n",
    "        best_weights2[2][i,:] = 0\n",
    "    else:\n",
    "        num_important += 1\n",
    "        imp += [i]\n",
    "\n",
    "tester_model2.set_weights(best_weights2)\n",
    "loss2, acc2 = tester_model2.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "y_pred = tester_model2.predict(x_test)\n",
    "\n",
    "K = len(set(y_test))\n",
    "yp = tf.argmax(y_pred, axis=1)\n",
    "acc = []\n",
    "for i in range(K):\n",
    "    a = np.mean((yp[y_test == i] == y_test[y_test == i]).numpy())\n",
    "    acc.append(a)\n",
    "print(acc)\n",
    "\n",
    "m = tf.keras.metrics.AUC()\n",
    "m.update_state(tf.one_hot(y_test, 10), y_pred)\n",
    "print(m.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 - 0s - loss: 0.2042 - accuracy: 0.9226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1024 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.855, 0.968, 0.861, 0.927, 0.738, 0.973, 0.677, 0.952, 0.969, 0.969]\n",
      "tf.Tensor(0.9906246, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1024/1024 [03:51<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.4497 - accuracy: 0.8302\n",
      "[0.645, 0.985, 0.572, 0.682, 0.857, 0.893, 0.846, 0.984, 0.971, 0.867]\n",
      "tf.Tensor(0.9865412, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "l, a = model2.evaluate(x_train, y_train, verbose=2, batch_size=256)\n",
    "\n",
    "y_pred = model2.predict(x_test)\n",
    "\n",
    "K = len(set(y_test))\n",
    "yp = tf.argmax(y_pred, axis=1)\n",
    "acc = []\n",
    "for i in range(K):\n",
    "    a = np.mean((yp[y_test == i] == y_test[y_test == i]).numpy())\n",
    "    acc.append(a)\n",
    "print(acc)\n",
    "\n",
    "m = tf.keras.metrics.AUC()\n",
    "m.update_state(tf.one_hot(y_test, 10), y_pred)\n",
    "print(m.result())\n",
    "\n",
    "or_weights = model2.get_weights()\n",
    "tol_low = -1e-5\n",
    "tol_high = 1e-5\n",
    "num_zeros, num_worse, num_important = (0, 0, 0)\n",
    "z = []\n",
    "wr = []\n",
    "imp = []\n",
    "best_weights2 = model2.get_weights()\n",
    "\n",
    "for i in tqdm.trange(size):\n",
    "    w = copy.deepcopy(or_weights)\n",
    "    w[0][:,i] = 0\n",
    "    w[1][i] = 0\n",
    "    w[2][i,:] = 0\n",
    "    tester_model2.set_weights(w)\n",
    "    nl, na = tester_model2.evaluate(x_train, y_train, verbose=0, batch_size=x_train.shape[0])\n",
    "    # print(f\"Node {i}:\", 1.*(na - a) + 0*(l - nl))\n",
    "    change = l - nl\n",
    "    if change <= tol_high and change >= tol_low:\n",
    "        num_zeros += 1\n",
    "        z += [i]\n",
    "        best_weights2[0][:,i] = 0\n",
    "        best_weights2[1][i] = 0\n",
    "        best_weights2[2][i,:] = 0\n",
    "    elif change > 0:\n",
    "        num_worse += 1\n",
    "        wr += [i]\n",
    "        best_weights2[0][:,i] = 0\n",
    "        best_weights2[1][i] = 0\n",
    "        best_weights2[2][i,:] = 0\n",
    "    else:\n",
    "        num_important += 1\n",
    "        imp += [i]\n",
    "\n",
    "tester_model2.set_weights(best_weights2)\n",
    "loss2, acc2 = tester_model2.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "y_pred = tester_model2.predict(x_test)\n",
    "\n",
    "K = len(set(y_test))\n",
    "yp = tf.argmax(y_pred, axis=1)\n",
    "acc = []\n",
    "for i in range(K):\n",
    "    a = np.mean((yp[y_test == i] == y_test[y_test == i]).numpy())\n",
    "    acc.append(a)\n",
    "print(acc)\n",
    "\n",
    "m = tf.keras.metrics.AUC()\n",
    "m.update_state(tf.one_hot(y_test, 10), y_pred)\n",
    "print(m.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.9207167>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.interpolate_pr_auc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(set(y_test))):\n",
    "    print(len(y_test[y_test==i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = tf.keras.datasets.cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "y_train, y_test = y_train.flatten(), y_test.flatten()\n",
    "y_train, y_test = tf.one_hot(y_train, 10), tf.one_hot(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(32, 32, 3)),\n",
    "        tf.keras.layers.Dense(size, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', tf.keras.metrics.AUC()])\n",
    "base_weights = model2.get_weights()\n",
    "#model2.fit(x_train, y_train, epochs=100, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester_model2 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(32, 32, 3)),\n",
    "        tf.keras.layers.Dense(size, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "tester_model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 - 0s - loss: 2.4628 - accuracy: 0.0822 - auc_35: 0.4969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.462815523147583, 0.08219999819993973, 0.4969491958618164]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(x_test, y_test, verbose=2, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 - 0s - loss: 2.2859 - accuracy: 0.1606 - auc_35: 0.5724\n"
     ]
    }
   ],
   "source": [
    "l, a, auc = model2.evaluate(x_test, y_test, verbose=2, batch_size=256)\n",
    "or_weights = model2.get_weights()\n",
    "tol_low = -1e-5\n",
    "tol_high = 1e-5\n",
    "num_zeros, num_worse, num_important = (0, 0, 0)\n",
    "z = []\n",
    "wr = []\n",
    "imp = []\n",
    "for i in range(size):\n",
    "    w = copy.deepcopy(or_weights)\n",
    "    w[0][:,i] = 0\n",
    "    w[1][i] = 0\n",
    "    w[2][i,:] = 0\n",
    "    tester_model2.set_weights(w)\n",
    "    nl, na, nauc = tester_model2.evaluate(x_test, y_test, verbose=0, batch_size=256)\n",
    "    # print(f\"Node {i}:\", 0.*(na - a) + 1.*(l - nl))\n",
    "    change = l - nl\n",
    "    if change <= tol_high and change >= tol_low:\n",
    "        num_zeros += 1\n",
    "        z += [i]\n",
    "    elif change > 0:\n",
    "        num_worse += 1\n",
    "        wr += [i]\n",
    "    else:\n",
    "        num_important += 1\n",
    "        imp += [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero Nodes: 48\n",
      "Worse Nodes: 5\n",
      "Important Nodes: 75\n"
     ]
    }
   ],
   "source": [
    "print(\"Zero Nodes:\", num_zeros)\n",
    "print(\"Worse Nodes:\", num_worse)\n",
    "print(\"Important Nodes:\", num_important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## WORSE NODES ########\n"
     ]
    }
   ],
   "source": [
    "print(\"######## WORSE NODES ########\")\n",
    "limit1 = np.sqrt(6 / (3200))\n",
    "limit2 = np.sqrt(6 / (138))\n",
    "w = copy.deepcopy(or_weights)\n",
    "for i in wr:\n",
    "    w[0][:,i] = list(np.random.uniform(-limit, limit, 3072))\n",
    "    w[1][i] = 0\n",
    "    w[2][i,:] = list(np.random.uniform(-limit, limit, 10))\n",
    "model2.set_weights(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.8554 - accuracy: 0.3289 - auc_35: 0.7858\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6917 - accuracy: 0.3952 - auc_35: 0.8293\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6301 - accuracy: 0.4200 - auc_35: 0.8431\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5900 - accuracy: 0.4339 - auc_35: 0.8516\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5651 - accuracy: 0.4434 - auc_35: 0.8566\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5436 - accuracy: 0.4531 - auc_35: 0.8610\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5251 - accuracy: 0.4583 - auc_35: 0.8646\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5075 - accuracy: 0.4657 - auc_35: 0.8680\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.4993 - accuracy: 0.4660 - auc_35: 0.8694\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.4869 - accuracy: 0.4719 - auc_35: 0.8719\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.4805 - accuracy: 0.4745 - auc_35: 0.8730\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.4679 - accuracy: 0.4808 - auc_35: 0.8753\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.4611 - accuracy: 0.4801 - auc_35: 0.8766\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.4524 - accuracy: 0.4827 - auc_35: 0.8780\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.4458 - accuracy: 0.4843 - auc_35: 0.8794\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.4424 - accuracy: 0.4877 - auc_35: 0.8800\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.4346 - accuracy: 0.4872 - auc_35: 0.8814\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.4270 - accuracy: 0.4936 - auc_35: 0.8827\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.4268 - accuracy: 0.4932 - auc_35: 0.8828\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.4187 - accuracy: 0.4940 - auc_35: 0.8842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x228ad6ee748>"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 - 0s - loss: 1.4929 - accuracy: 0.4737 - auc_35: 0.8716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4928829669952393, 0.47369998693466187, 0.8715860247612]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(x_test, y_test, verbose=2, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8985 - accuracy: 0.3226 - auc_37: 0.7730\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7529 - accuracy: 0.3762 - auc_37: 0.8142\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6944 - accuracy: 0.3975 - auc_37: 0.8281\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6618 - accuracy: 0.4074 - auc_37: 0.8358\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6320 - accuracy: 0.4193 - auc_37: 0.8424\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6089 - accuracy: 0.4270 - auc_37: 0.8474\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5892 - accuracy: 0.4332 - auc_37: 0.8516\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5797 - accuracy: 0.4375 - auc_37: 0.8535\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5686 - accuracy: 0.4399 - auc_37: 0.8559\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5575 - accuracy: 0.4437 - auc_37: 0.8580\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5473 - accuracy: 0.4465 - auc_37: 0.8603\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5442 - accuracy: 0.4498 - auc_37: 0.8608\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5378 - accuracy: 0.4527 - auc_37: 0.8621\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5280 - accuracy: 0.4557 - auc_37: 0.8639\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5245 - accuracy: 0.4566 - auc_37: 0.8646\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5219 - accuracy: 0.4576 - auc_37: 0.8652\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5181 - accuracy: 0.4610 - auc_37: 0.8658\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5137 - accuracy: 0.4611 - auc_37: 0.8666\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5130 - accuracy: 0.4603 - auc_37: 0.8669\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5025 - accuracy: 0.4642 - auc_37: 0.8687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x228ae5a3a08>"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blank_model2 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(32, 32, 3)),\n",
    "        tf.keras.layers.Dense(size, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "blank_model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', tf.keras.metrics.AUC()])\n",
    "blank_model2.set_weights(base_weights)\n",
    "blank_model2.fit(x_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 - 0s - loss: 1.5919 - accuracy: 0.4362 - auc_37: 0.8523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5918580293655396, 0.43619999289512634, 0.8522675037384033]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blank_model2.evaluate(x_test, y_test, verbose=2, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(32, 32, 3)),\n",
    "        tf.keras.layers.Dense(size, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', tf.keras.metrics.AUC()])\n",
    "model2.set_weights(base_weights)\n",
    "#model2.fit(x_train, y_train, epochs=100, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester_model2 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(32, 32, 3)),\n",
    "        tf.keras.layers.Dense(size, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "tester_model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 - 0s - loss: 2.4628 - accuracy: 0.0822 - auc_38: 0.4969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.462815523147583, 0.08219999819993973, 0.4969491958618164]"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(x_test, y_test, verbose=2, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 - 0s - loss: 2.9021 - accuracy: 0.1000 - auc_38: 0.4924\n"
     ]
    }
   ],
   "source": [
    "l, a, auc = model2.evaluate(x_test, y_test, verbose=2, batch_size=256)\n",
    "or_weights = model2.get_weights()\n",
    "tol_low = -1e-5\n",
    "tol_high = 1e-5\n",
    "num_zeros, num_worse, num_important = (0, 0, 0)\n",
    "z = []\n",
    "wr = []\n",
    "imp = []\n",
    "for i in range(size):\n",
    "    w = copy.deepcopy(or_weights)\n",
    "    w[0][:,i] = 0\n",
    "    w[1][i] = 0\n",
    "    w[2][i,:] = 0\n",
    "    tester_model2.set_weights(w)\n",
    "    nl, na, nauc = tester_model2.evaluate(x_test, y_test, verbose=0, batch_size=256)\n",
    "    # print(f\"Node {i}:\", 0.*(na - a) + 1.*(l - nl))\n",
    "    change = l - nl\n",
    "    if change <= tol_high and change >= tol_low:\n",
    "        num_zeros += 1\n",
    "        z += [i]\n",
    "    elif change > 0:\n",
    "        num_worse += 1\n",
    "        wr += [i]\n",
    "    else:\n",
    "        num_important += 1\n",
    "        imp += [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero Nodes: 22\n",
      "Worse Nodes: 105\n",
      "Important Nodes: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Zero Nodes:\", num_zeros)\n",
    "print(\"Worse Nodes:\", num_worse)\n",
    "print(\"Important Nodes:\", num_important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## WORSE NODES ########\n"
     ]
    }
   ],
   "source": [
    "print(\"######## WORSE NODES ########\")\n",
    "limit1 = np.sqrt(6 / (3200))\n",
    "limit2 = np.sqrt(6 / (138))\n",
    "w = copy.deepcopy(or_weights)\n",
    "for i in imp:\n",
    "    w[0][:,i] = list(np.random.uniform(-limit, limit, 3072))\n",
    "    w[1][i] = 0\n",
    "    w[2][i,:] = list(np.random.uniform(-limit, limit, 10))\n",
    "model2.set_weights(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.9313 - accuracy: 0.2985 - auc_38: 0.7622\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.8093 - accuracy: 0.3526 - auc_38: 0.7996\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7746 - accuracy: 0.3642 - auc_38: 0.8083\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7514 - accuracy: 0.3726 - auc_38: 0.8144\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7362 - accuracy: 0.3758 - auc_38: 0.8182\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7258 - accuracy: 0.3804 - auc_38: 0.8210\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7183 - accuracy: 0.3819 - auc_38: 0.8229\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7110 - accuracy: 0.3846 - auc_38: 0.8245\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7065 - accuracy: 0.3855 - auc_38: 0.8254\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7014 - accuracy: 0.3876 - auc_38: 0.8267\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6962 - accuracy: 0.3914 - auc_38: 0.8280\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6903 - accuracy: 0.3950 - auc_38: 0.8292\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6898 - accuracy: 0.3954 - auc_38: 0.8294\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6840 - accuracy: 0.3936 - auc_38: 0.8306\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6818 - accuracy: 0.3970 - auc_38: 0.8313\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6800 - accuracy: 0.3964 - auc_38: 0.8316\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6777 - accuracy: 0.3959 - auc_38: 0.8322\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6738 - accuracy: 0.3968 - auc_38: 0.8332\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6711 - accuracy: 0.4001 - auc_38: 0.8337\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6710 - accuracy: 0.3989 - auc_38: 0.8338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x228b3668f08>"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 - 0s - loss: 1.7089 - accuracy: 0.3864 - auc_38: 0.8248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7089338302612305, 0.3864000141620636, 0.8247711062431335]"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(x_test, y_test, verbose=2, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 - 0s - loss: 1.6823 - accuracy: 0.3956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\Anaconda3\\envs\\master\\lib\\site-packages\\ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b4d19b06794cd594eae0737dfd3f6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=64.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "l, a = model2.evaluate(x_test, y_test, verbose=2, batch_size=256)\n",
    "tol_low = -1e-5\n",
    "tol_high = 1e-5\n",
    "num_zeros, num_worse, num_important = (0, 0, 0)\n",
    "z = []\n",
    "wr = []\n",
    "imp = []\n",
    "for i in tqdm.tqdm_notebook(range(size)):\n",
    "    w = copy.deepcopy(or_weights)\n",
    "    w[0][:,i] = 0\n",
    "    w[1][i] = 0\n",
    "    w[2][i,:] = 0\n",
    "    tester_model2.set_weights(w)\n",
    "    nl, na = tester_model2.evaluate(x_test, y_test, verbose=0, batch_size=256)\n",
    "    # print(f\"Node {i}:\", 0.*(na - a) + 1.*(l - nl))\n",
    "    change = l - nl\n",
    "    if change <= tol_high and change >= tol_low:\n",
    "        num_zeros += 1\n",
    "        z += [i]\n",
    "    elif change > 0:\n",
    "        num_worse += 1\n",
    "        wr += [i]\n",
    "    else:\n",
    "        num_important += 1\n",
    "        imp += [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero Nodes: 0\n",
      "Worse Nodes: 0\n",
      "Important Nodes: 64\n"
     ]
    }
   ],
   "source": [
    "print(\"Zero Nodes:\", num_zeros)\n",
    "print(\"Worse Nodes:\", num_worse)\n",
    "print(\"Important Nodes:\", num_important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## WORSE NODES ########\n"
     ]
    }
   ],
   "source": [
    "print(\"######## WORSE NODES ########\")\n",
    "limit1 = np.sqrt(6 / (3200))\n",
    "limit2 = np.sqrt(6 / (138))\n",
    "w = copy.deepcopy(or_weights)\n",
    "for i in wr:\n",
    "    w[0][:,i] = list(np.random.uniform(-limit, limit, 3072))\n",
    "    w[1][i] = 0\n",
    "    w[2][i,:] = list(np.random.uniform(-limit, limit, 10))\n",
    "model2.set_weights(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 - 0s - loss: 2.3971 - accuracy: 0.0869\n",
      "0.006078667193651199\n",
      "Found something better\n",
      "0.007046357542276381\n",
      "Found something better\n",
      "0.013568452745676038\n",
      "Found something better\n",
      "0.017282692342996595\n",
      "Found something better\n",
      "0.020366835594177242\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.08150000125169754 --- Loss: 2.365630865097046 --- Change: 0.020366835594177242 --- New tol: -1e-05\n",
      "0.005944054573774338\n",
      "Found something better\n",
      "0.009405882656574249\n",
      "Found something better\n",
      "0.011495045572519302\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.09839999675750732 --- Loss: 2.356452226638794 --- Change: 0.011495045572519302 --- New tol: -1e-05\n",
      "0.003387662023305893\n",
      "Found something better\n",
      "0.004780366271734238\n",
      "Found something better\n",
      "0.0072697028517723075\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.10369999706745148 --- Loss: 2.3483383655548096 --- Change: 0.0072697028517723075 --- New tol: -1e-05\n",
      "0.0024870097637176513\n",
      "Found something better\n",
      "0.0051490552723407745\n",
      "Found something better\n",
      "0.005376225709915161\n",
      "Found something better\n",
      "0.006661739945411682\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.10320000350475311 --- Loss: 2.3386073112487793 --- Change: 0.006661739945411682 --- New tol: -1e-05\n",
      "0.0010549925267696381\n",
      "Found something better\n",
      "0.004032516479492187\n",
      "Found something better\n",
      "0.004507363587617874\n",
      "Found something better\n",
      "0.004658913612365722\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.10459999740123749 --- Loss: 2.3325517177581787 --- Change: 0.004658913612365722 --- New tol: -1e-05\n",
      "0.0009391687810420989\n",
      "Found something better\n",
      "0.003973271697759628\n",
      "Found something better\n",
      "0.00426206961274147\n",
      "Found something better\n",
      "0.004318276047706604\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.10480000078678131 --- Loss: 2.3264684677124023 --- Change: 0.004318276047706604 --- New tol: -1e-05\n",
      "0.0007365681231021881\n",
      "Found something better\n",
      "0.0015582837164402007\n",
      "Found something better\n",
      "0.004004020243883133\n",
      "Found something better\n",
      "0.004525764286518096\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.10490000247955322 --- Loss: 2.3200459480285645 --- Change: 0.004525764286518096 --- New tol: -1e-05\n",
      "0.00016967281699180602\n",
      "Found something better\n",
      "0.0015909545123577117\n",
      "Found something better\n",
      "0.0038161002099514002\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.10589999705553055 --- Loss: 2.3150229454040527 --- Change: 0.0038161002099514002 --- New tol: -1e-05\n",
      "0.00012632310390472414\n",
      "Found something better\n",
      "0.0016396470367908476\n",
      "Found something better\n",
      "0.0027557916939258574\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.10289999842643738 --- Loss: 2.309800386428833 --- Change: 0.0027557916939258574 --- New tol: -1e-05\n",
      "5.674362182617187e-06\n",
      "Found something better\n",
      "0.0017653286457061765\n",
      "Found something better\n",
      "0.0018304057419300077\n",
      "Found something better\n",
      "0.0020942419767379762\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.10559999942779541 --- Loss: 2.3079657554626465 --- Change: 0.0020942419767379762 --- New tol: -1e-05\n",
      "5.674362182617187e-06\n",
      "Found something better\n",
      "0.001665522903203964\n",
      "Found something better\n",
      "0.0018998332321643826\n",
      "Found something better\n",
      "0.0021276786923408505\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.10570000112056732 --- Loss: 2.304969072341919 --- Change: 0.0021276786923408505 --- New tol: -1e-05\n",
      "5.340576171875e-06\n",
      "Found something better\n",
      "0.001283324509859085\n",
      "Found something better\n",
      "0.0014021195471286773\n",
      "Found something better\n",
      "0.002856025844812393\n",
      "Found something better\n",
      "0.0032587707042694095\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.12039999663829803 --- Loss: 2.3066136837005615 --- Change: 0.0032587707042694095 --- New tol: -1e-05\n",
      "5.674362182617187e-06\n",
      "Found something better\n",
      "0.001452433317899704\n",
      "Found something better\n",
      "0.0015679158270359038\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.1200999990105629 --- Loss: 2.3042452335357666 --- Change: 0.0015679158270359038 --- New tol: -1e-05\n",
      "5.841255187988281e-06\n",
      "Found something better\n",
      "0.0015048816800117492\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.120899997651577 --- Loss: 2.302438259124756 --- Change: 0.0015048816800117492 --- New tol: -1e-05\n",
      "5.507469177246093e-06\n",
      "Found something better\n",
      "2.5661289691925047e-05\n",
      "Found something better\n",
      "0.0009041570127010345\n",
      "Found something better\n",
      "0.00092763751745224\n",
      "Found something better\n",
      "0.0013319440186023712\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.12219999730587006 --- Loss: 2.3010926246643066 --- Change: 0.0013319440186023712 --- New tol: -1e-05\n",
      "2.828761935234069e-05\n",
      "Found something better\n",
      "0.0010481491684913634\n",
      "Found something better\n",
      "0.0012599870562553406\n",
      "Found something better\n",
      "0.0013084515929222106\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.1274999976158142 --- Loss: 2.301494836807251 --- Change: 0.0013084515929222106 --- New tol: -1e-05\n",
      "0.00013256072998046875\n",
      "Found something better\n",
      "0.0011702358722686767\n",
      "Found something better\n",
      "0.0012351498007774353\n",
      "Found something better\n",
      "0.0016276210546493529\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.12729999423027039 --- Loss: 2.299083948135376 --- Change: 0.0016276210546493529 --- New tol: -1e-05\n",
      "5.507469177246093e-06\n",
      "Found something better\n",
      "5.432665348052979e-05\n",
      "Found something better\n",
      "0.0010795712471008301\n",
      "Found something better\n",
      "0.0011146515607833862\n",
      "Found something better\n",
      "0.001600004732608795\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.131400004029274 --- Loss: 2.298555374145508 --- Change: 0.001600004732608795 --- New tol: -1e-05\n",
      "5.507469177246093e-06\n",
      "Found something better\n",
      "2.3658573627471925e-05\n",
      "Found something better\n",
      "0.0008404016494750976\n",
      "Found something better\n",
      "0.0009053558111190795\n",
      "Found something better\n",
      "0.0010016188025474548\n",
      "Found something better\n",
      "0.0011307552456855773\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.13289999961853027 --- Loss: 2.2975828647613525 --- Change: 0.0011307552456855773 --- New tol: -1e-05\n",
      "5.674362182617187e-06\n",
      "Found something better\n",
      "2.382546663284302e-05\n",
      "Found something better\n",
      "0.0006924062967300414\n",
      "Found something better\n",
      "0.0010196834802627562\n",
      "Found something better\n",
      "0.0010849446058273315\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.13420000672340393 --- Loss: 2.2965900897979736 --- Change: 0.0010849446058273315 --- New tol: -1e-05\n",
      "5.507469177246093e-06\n",
      "Found something better\n",
      "0.0007850736379623412\n",
      "Found something better\n",
      "0.0009658575057983397\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.13490000367164612 --- Loss: 2.2955102920532227 --- Change: 0.0009658575057983397 --- New tol: -1e-05\n",
      "3.5341084003448484e-05\n",
      "Found something better\n",
      "0.0007162317633628845\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.13590000569820404 --- Loss: 2.2949156761169434 --- Change: 0.0007162317633628845 --- New tol: -1e-05\n",
      "5.507469177246093e-06\n",
      "Found something better\n",
      "0.00015174746513366697\n",
      "Found something better\n",
      "0.0008521854877471923\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.13910000026226044 --- Loss: 2.295069694519043 --- Change: 0.0008521854877471923 --- New tol: -1e-05\n",
      "5.507469177246093e-06\n",
      "Found something better\n",
      "0.00018292069435119627\n",
      "Found something better\n",
      "0.00038335919380187987\n",
      "Found something better\n",
      "0.0007031738758087158\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.14020000398159027 --- Loss: 2.294536590576172 --- Change: 0.0007031738758087158 --- New tol: -1e-05\n",
      "5.340576171875e-06\n",
      "Found something better\n",
      "0.00018308311700820923\n",
      "Found something better\n",
      "0.00044452399015426636\n",
      "Found something better\n",
      "0.0006758838891983032\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.14110000431537628 --- Loss: 2.293956756591797 --- Change: 0.0006758838891983032 --- New tol: -1e-05\n",
      "5.674362182617187e-06\n",
      "Found something better\n",
      "0.00018441826105117796\n",
      "Found something better\n",
      "0.0004455253481864929\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.14169999957084656 --- Loss: 2.2935774326324463 --- Change: 0.0004455253481864929 --- New tol: -1e-05\n",
      "5.507469177246093e-06\n",
      "Found something better\n",
      "9.475499391555786e-05\n",
      "Found something better\n",
      "0.00011182427406311035\n",
      "Found something better\n",
      "0.00012171119451522827\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.1420000046491623 --- Loss: 2.293532133102417 --- Change: 0.00012171119451522827 --- New tol: -1e-05\n",
      "5.674362182617187e-06\n",
      "Found something better\n",
      "9.508877992630005e-05\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.1421000063419342 --- Loss: 2.2934391498565674 --- Change: 9.508877992630005e-05 --- New tol: -1e-05\n",
      "5.173683166503906e-06\n",
      "Found something better\n",
      "3.333389759063721e-05\n",
      "Found something better\n",
      "8.165240287780761e-05\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.14239999651908875 --- Loss: 2.2934510707855225 --- Change: 8.165240287780761e-05 --- New tol: -1e-05\n",
      "5.674362182617187e-06\n",
      "Found something better\n",
      "2.3324787616729736e-05\n",
      "Found something better\n",
      "3.3505260944366455e-05\n",
      "Found something better\n",
      "5.7664513587951656e-05\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.14259999990463257 --- Loss: 2.29345440864563 --- Change: 5.7664513587951656e-05 --- New tol: -1e-05\n",
      "5.674362182617187e-06\n",
      "Found something better\n",
      "2.3324787616729736e-05\n",
      "Found something better\n",
      "3.3839046955108644e-05\n",
      "Found something better\n",
      "3.4362077713012695e-05\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.14509999752044678 --- Loss: 2.2944767475128174 --- Change: 3.4362077713012695e-05 --- New tol: -1e-05\n",
      "5.340576171875e-06\n",
      "Found something better\n",
      "2.299100160598755e-05\n",
      "Found something better\n",
      "3.3171474933624266e-05\n",
      "Found something better\n",
      "3.3672153949737546e-05\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.1451999992132187 --- Loss: 2.294471502304077 --- Change: 3.3672153949737546e-05 --- New tol: -1e-05\n",
      "5.674362182617187e-06\n",
      "Found something better\n",
      "7.176399230957031e-06\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.1451999992132187 --- Loss: 2.294461250305176 --- Change: 7.176399230957031e-06 --- New tol: -1e-05\n",
      "5.674362182617187e-06\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.1451999992132187 --- Loss: 2.2944531440734863 --- Change: 5.674362182617187e-06 --- New tol: -1e-05\n",
      "-7.176399230957031e-06\n",
      "Found something better\n",
      "-1.1682510375976561e-06\n",
      "Found something better\n",
      "3.337860107421875e-06\n",
      "Found something better\n",
      "5.340576171875e-06\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.1451999992132187 --- Loss: 2.294445514678955 --- Change: 5.340576171875e-06 --- New tol: -1e-05\n",
      "-7.009506225585937e-06\n",
      "Found something better\n",
      "-1.1682510375976561e-06\n",
      "Found something better\n",
      "3.337860107421875e-06\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.1451999992132187 --- Loss: 2.294440746307373 --- Change: 3.337860107421875e-06 --- New tol: -1e-05\n",
      "-7.343292236328124e-06\n",
      "Found something better\n",
      "-1.5020370483398437e-06\n",
      "Found something better\n",
      "0.0\n",
      "Found something better\n",
      "1.1682510375976561e-06\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.1451999992132187 --- Loss: 2.2944390773773193 --- Change: 1.1682510375976561e-06 --- New tol: -1e-05\n",
      "-7.176399230957031e-06\n",
      "Found something better\n",
      "-1.33514404296875e-06\n",
      "Found something better\n",
      "0.0\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.1451999992132187 --- Loss: 2.2944390773773193 --- Change: 0.0 --- New tol: -1e-05\n",
      "-7.176399230957031e-06\n",
      "Found something better\n",
      "-1.33514404296875e-06\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.1451999992132187 --- Loss: 2.294440984725952 --- Change: -1.33514404296875e-06 --- New tol: -1e-05\n",
      "-7.176399230957031e-06\n",
      "Found something better\n",
      "Improvement has occured!! Accuracy: 0.1451999992132187 --- Loss: 2.2944512367248535 --- Change: -7.176399230957031e-06 --- New tol: -1e-05\n",
      "313/313 - 0s - loss: 2.2945 - accuracy: 0.1452\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model2.evaluate(x_train, y_train, verbose=2, batch_size=512)\n",
    "end_not_reached = True\n",
    "improved = False\n",
    "tol = -1e-5\n",
    "current_pos = 0\n",
    "best_pos = -1\n",
    "best_change = tol\n",
    "original2 = model2.get_weights()\n",
    "bas2 = [acc]\n",
    "bls2 = [loss]\n",
    "best_weights2 = model2.get_weights()\n",
    "nodes_removed2 = []\n",
    "best_acc = 0\n",
    "best_loss = 1e20\n",
    "ol = loss\n",
    "oa = acc\n",
    "num_removed2 = 0\n",
    "while end_not_reached or improved:\n",
    "    if not(end_not_reached):\n",
    "        end_not_reached = True\n",
    "        improved = False\n",
    "        current_pos = 0\n",
    "        size -= 1\n",
    "        nodes_removed2 += [best_pos]\n",
    "        best_weights2[0][:,best_pos] = 0\n",
    "        best_weights2[1][best_pos] = 0\n",
    "        best_weights2[2][best_pos,:] = 0\n",
    "        best_pos = -1\n",
    "        #tol -= best_change\n",
    "        ol = best_loss\n",
    "        oa = best_acc\n",
    "        bas2 += [best_acc]\n",
    "        bls2 += [best_loss]\n",
    "        print(\"Improvement has occured!! Accuracy:\", best_acc, \"--- Loss:\", best_loss, '--- Change:', best_change, '--- New tol:', tol)\n",
    "        best_change = tol\n",
    "        num_removed2 += 1\n",
    "    if current_pos in nodes_removed2:\n",
    "        current_pos += 1\n",
    "        if current_pos - num_removed2 >= size:\n",
    "            end_not_reached = False\n",
    "        continue\n",
    "    w = copy.deepcopy(best_weights2)\n",
    "    w[0][:,current_pos] = 0\n",
    "    w[1][current_pos] = 0\n",
    "    w[2][current_pos,:] = 0\n",
    "    tester_model2.set_weights(w)\n",
    "    nl, na = tester_model2.evaluate(x_test, y_test, verbose=0, batch_size=1024)\n",
    "    if 0.3*(na - oa) + 0.7*(ol - nl) > best_change:\n",
    "        best_change = 0.3*(na - oa) + 0.7*(ol - nl)\n",
    "        print(best_change)\n",
    "        best_pos = current_pos\n",
    "        improved = True\n",
    "        best_acc = na\n",
    "        best_loss = nl\n",
    "        print(\"Found something better\")\n",
    "    current_pos += 1\n",
    "    if current_pos - num_removed2 >= size:\n",
    "        end_not_reached = False\n",
    "    if current_pos%200 == 0:\n",
    "        print(\"Did 200 iterations\")\n",
    "\n",
    "tester_model2.set_weights(best_weights2)\n",
    "loss2, acc2 = tester_model2.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weights = [np.zeros((best_weights2[0].shape[0], best_weights2[0].shape[1] - num_removed2)),\n",
    "               np.zeros((best_weights2[1].shape[0] - num_removed2)),\n",
    "               np.zeros((best_weights2[2].shape[0] - num_removed2, best_weights2[2].shape[1])),\n",
    "               best_weights2[3]]\n",
    "\n",
    "j = 0\n",
    "for i in range(len(best_weights2[1])):\n",
    "    if i not in nodes_removed2:\n",
    "        new_weights[0][:, j] = best_weights2[0][:, i]\n",
    "        new_weights[1][j] = best_weights2[1][i]\n",
    "        new_weights[2][j, :] = best_weights2[2][i, :]\n",
    "        j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 2.2945 - accuracy: 0.1452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2944507598876953, 0.1451999992132187]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(32, 32, 3)),\n",
    "        tf.keras.layers.Dense(size, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "red_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "red_model.set_weights(new_weights)\n",
    "red_model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_removed2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 1.8282 - accuracy: 0.3363\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 1.8217 - accuracy: 0.3417\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 1.8176 - accuracy: 0.3409\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 1.8143 - accuracy: 0.3409\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.8111 - accuracy: 0.3441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x228c3d543c8>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 1.8012 - accuracy: 0.3435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8012312650680542, 0.3434999883174896]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_weights = red_model.get_weights()\n",
    "model2 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(32, 32, 3)),\n",
    "        tf.keras.layers.Dense(size, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model2.set_weights(new_weights)\n",
    "model2.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester_model2 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(32, 32, 3)),\n",
    "        tf.keras.layers.Dense(size, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "tester_model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 - 0s - loss: 1.7879 - accuracy: 0.3527\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model2.evaluate(x_train, y_train, verbose=2, batch_size=512)\n",
    "end_not_reached = True\n",
    "improved = False\n",
    "tol = -1e-5\n",
    "current_pos = 0\n",
    "best_pos = -1\n",
    "best_change = tol\n",
    "original2 = model2.get_weights()\n",
    "bas2 = [acc]\n",
    "bls2 = [loss]\n",
    "best_weights2 = model2.get_weights()\n",
    "nodes_removed2 = []\n",
    "best_acc = 0\n",
    "best_loss = 1e20\n",
    "ol = loss\n",
    "oa = acc\n",
    "num_removed2 = 0\n",
    "while end_not_reached or improved:\n",
    "    if not(end_not_reached):\n",
    "        end_not_reached = True\n",
    "        improved = False\n",
    "        current_pos = 0\n",
    "        size -= 1\n",
    "        nodes_removed2 += [best_pos]\n",
    "        best_weights2[0][:,best_pos] = 0\n",
    "        best_weights2[1][best_pos] = 0\n",
    "        best_weights2[2][best_pos,:] = 0\n",
    "        best_pos = -1\n",
    "        #tol -= best_change\n",
    "        ol = best_loss\n",
    "        oa = best_acc\n",
    "        bas2 += [best_acc]\n",
    "        bls2 += [best_loss]\n",
    "        print(\"Improvement has occured!! Accuracy:\", best_acc, \"--- Loss:\", best_loss, '--- Change:', best_change, '--- New tol:', tol)\n",
    "        best_change = tol\n",
    "        num_removed2 += 1\n",
    "    if current_pos in nodes_removed2:\n",
    "        current_pos += 1\n",
    "        if current_pos - num_removed2 >= size:\n",
    "            end_not_reached = False\n",
    "        continue\n",
    "    w = copy.deepcopy(best_weights2)\n",
    "    w[0][:,current_pos] = 0\n",
    "    w[1][current_pos] = 0\n",
    "    w[2][current_pos,:] = 0\n",
    "    tester_model2.set_weights(w)\n",
    "    nl, na = tester_model2.evaluate(x_test, y_test, verbose=0, batch_size=1024)\n",
    "    if 0.*(na - oa) + 1.*(ol - nl) > best_change:\n",
    "        best_change = 0.*(na - oa) + 1.*(ol - nl)\n",
    "        print(best_change)\n",
    "        best_pos = current_pos\n",
    "        improved = True\n",
    "        best_acc = na\n",
    "        best_loss = nl\n",
    "        print(\"Found something better\")\n",
    "    current_pos += 1\n",
    "    if current_pos - num_removed2 >= size:\n",
    "        end_not_reached = False\n",
    "    if current_pos%200 == 0:\n",
    "        print(\"Did 200 iterations\")\n",
    "\n",
    "tester_model2.set_weights(best_weights2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('master': conda)",
   "language": "python",
   "name": "python37664bitmastercondad556aba890334ca2b025f74f5b164268"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
