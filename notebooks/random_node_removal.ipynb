{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "from __future__ import unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import copy\n",
    "import tqdm\n",
    "import IProgress\n",
    "from hfunc import models\n",
    "from hfunc import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "class_accuracy = metrics.ClassAccuracy()\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Converting interger values to floats (0 to 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/10\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.2629 - accuracy: 0.9239 - val_loss: 0.1469 - val_accuracy: 0.9564\nEpoch 2/10\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.1161 - accuracy: 0.9654 - val_loss: 0.1096 - val_accuracy: 0.9678\nEpoch 3/10\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0798 - accuracy: 0.9766 - val_loss: 0.0920 - val_accuracy: 0.9734\nEpoch 4/10\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0591 - accuracy: 0.9821 - val_loss: 0.0774 - val_accuracy: 0.9777\nEpoch 5/10\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0459 - accuracy: 0.9861 - val_loss: 0.0743 - val_accuracy: 0.9782\nEpoch 6/10\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0359 - accuracy: 0.9890 - val_loss: 0.0821 - val_accuracy: 0.9766\nEpoch 7/10\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0291 - accuracy: 0.9910 - val_loss: 0.0731 - val_accuracy: 0.9788\nEpoch 8/10\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 0.0777 - val_accuracy: 0.9789\nEpoch 9/10\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0191 - accuracy: 0.9943 - val_loss: 0.0781 - val_accuracy: 0.9785\nEpoch 10/10\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0169 - accuracy: 0.9946 - val_loss: 0.0762 - val_accuracy: 0.9795\n"
    }
   ],
   "source": [
    "model, r = models.train_basic_ANN(x_train, y_train, 128, (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "313/313 - 1s - loss: 0.0762 - accuracy: 0.9795\n"
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "old = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_random_nodes(acc, loss, weights, n, to_test, x_train, y_train, v=0, remove='positive'):\n",
    "    new_loss = loss\n",
    "    new_acc = acc\n",
    "    if remove == 'positive':\n",
    "        best_score = 0\n",
    "    elif remove == 'always':\n",
    "        best_score = -1e20\n",
    "    else:\n",
    "        best_score = 0.5\n",
    "    best_model = copy.deepcopy(weights)\n",
    "    nodes_removed = np.array([])\n",
    "    for _ in tqdm.trange(to_test):   \n",
    "        new = copy.deepcopy(weights)\n",
    "        to_drop = np.random.choice(len(new[1]), n, replace=False)\n",
    "        for i in to_drop:\n",
    "            new[0][:,i] = 0\n",
    "            new[1][i] = 0\n",
    "            new[2][i,:] = 0\n",
    "        model.set_weights(new)\n",
    "        new_loss, new_acc = model.evaluate(x_train, y_train, verbose=v)\n",
    "        score = (1 - (new_loss / loss)) + ((new_acc / acc) - 1)\n",
    "        if best_score < score:\n",
    "            best_score = score\n",
    "            best_model = copy.deepcopy(new)\n",
    "            nodes_removed = to_drop.copy()\n",
    "    return best_model, best_score, nodes_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "0%|          | 0/100 [00:00<?, ?it/s]\n"
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'check' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-9ea0a0003e5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mbest_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'check' is not defined"
     ]
    }
   ],
   "source": [
    "to_check = 100\n",
    "new_loss = loss\n",
    "new_acc = acc\n",
    "best_score = 0\n",
    "best_model = copy.deepcopy(old)\n",
    "\n",
    "for i in tqdm.trange(to_check):   \n",
    "    new = copy.deepcopy(old)\n",
    "    #for i in range(len(old)):\n",
    "    #    new[i] = old[i].copy()\n",
    "    to_drop = np.random.choice(len(new[1]), n, replace=False)\n",
    "    # for i in to_drop:\n",
    "    new[0][:,i] = 0\n",
    "    new[1][i] = 0\n",
    "    new[2][i,:] = 0\n",
    "    model.set_weights(new)\n",
    "    new_loss, new_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "    score = (1 - (new_loss / loss)) + ((new_acc / acc) - 1)\n",
    "    score1 = (1 - (new_loss / loss))\n",
    "    score2 = ((new_acc / acc) - 1)\n",
    "    if best_score < score1 or best_score < score2:\n",
    "        best_score = score1\n",
    "        best_model = copy.deepcopy(new)\n",
    "    if best_score < score2:\n",
    "        best_score = score2\n",
    "        best_model = copy.deepcopy(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights(best_model)\n",
    "loss, acc = model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 25/25 [00:44<00:00,  1.78s/it]\n  0%|          | 0/25 [00:00<?, ?it/s]Found new best model\n100%|██████████| 25/25 [00:45<00:00,  1.82s/it]\n100%|██████████| 25/25 [00:45<00:00,  1.81s/it]\n100%|██████████| 25/25 [00:45<00:00,  1.83s/it]\n100%|██████████| 25/25 [00:45<00:00,  1.83s/it]\n100%|██████████| 25/25 [00:48<00:00,  1.93s/it]\n100%|██████████| 25/25 [00:43<00:00,  1.73s/it]\n100%|██████████| 25/25 [00:43<00:00,  1.72s/it]\n  4%|▍         | 1/25 [00:02<01:10,  2.93s/it]\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-a29f52a441a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mto_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m65\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mtemp_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodes_removed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremove_random_nodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtemp_score\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-542a51b331ab>\u001b[0m in \u001b[0;36mremove_random_nodes\u001b[1;34m(acc, loss, weights, n, to_test, x_train, y_train, v)\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mnew\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mnew_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnew_loss\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_acc\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbest_score\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1079\u001b[0m                 step_num=step):\n\u001b[0;32m   1080\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1081\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    616\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_model = copy.deepcopy(old)\n",
    "to_test = 25\n",
    "for i in range(1, 65):\n",
    "    temp_model, temp_score, nodes_removed = remove_random_nodes(acc, loss, old, i, to_test, x_train, y_train)\n",
    "    if temp_score > best_score:\n",
    "        best_model = temp_model\n",
    "        best_score = temp_score\n",
    "        print(\"Found new best model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([ 0.13777253,  0.00683018, -0.04688663, -0.0542522 , -0.02874556,\n       -0.06947239,  0.26529318, -0.05660995, -0.12442102, -0.00682503,\n       -0.06165336,  0.04902135, -0.06425561,  0.1148253 ,  0.10713325,\n       -0.03243035,  0.13046843, -0.02118045,  0.23898   ,  0.012234  ,\n       -0.00759443,  0.0615023 ,  0.19653296,  0.0889185 ,  0.11125184,\n        0.01821019, -0.06034907, -0.01788706, -0.22678226,  0.25768587,\n       -0.00749901, -0.15829737,  0.08297709,  0.07035011,  0.19038919,\n        0.21002766,  0.0498327 , -0.16142973, -0.02738184, -0.0705651 ,\n       -0.05639892,  0.14290817, -0.04814705, -0.05610737,  0.02354445,\n       -0.03746689,  0.07436547,  0.04749129,  0.00861628, -0.00861224,\n       -0.02170092,  0.09200769,  0.15906057, -0.13180414, -0.07231998,\n       -0.01664761, -0.00881143,  0.10944258,  0.00742158, -0.10521833,\n        0.11596415, -0.00629094,  0.04692442,  0.00971017,  0.01094389,\n       -0.02010831,  0.13656658,  0.06641621, -0.1453644 , -0.01762852,\n       -0.21220163, -0.21188964, -0.11585108, -0.13904442,  0.08208026,\n       -0.00362335, -0.06280398,  0.18336907,  0.03077355, -0.00404131,\n        0.01833009, -0.2368721 ,  0.17968902,  0.07943354, -0.03933392,\n        0.10595421,  0.15646923,  0.15681233,  0.00495485,  0.08285215,\n        0.        ,  0.16648453, -0.00855367, -0.06806661,  0.00347185,\n       -0.02769154,  0.06922228,  0.18027121, -0.07102263, -0.05593982,\n        0.14157607,  0.14092448, -0.01556914,  0.18738736, -0.04562042,\n        0.11141061,  0.03112996, -0.06217255,  0.06744141,  0.07489815,\n        0.00297301, -0.03798772,  0.16891876,  0.09960993,  0.15761662,\n        0.07061482,  0.04800729, -0.12262462, -0.01059775,  0.10449447,\n        0.24172989,  0.22352731,  0.01824049,  0.06282635, -0.17810178,\n        0.04480168, -0.00173648, -0.08439755], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "best_model[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a restriced model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 50/50 [01:32<00:00,  1.85s/it]\n"
    }
   ],
   "source": [
    "n = 2\n",
    "best_weights, _, nodes_removed = remove_random_nodes(acc, loss, old, n, 50, x_train, y_train)\n",
    "\n",
    "new_weights = [np.zeros((best_weights[0].shape[0], best_weights[0].shape[1] - n)), np.zeros((best_weights[1].shape[0] - n)), np.zeros((best_weights[2].shape[0] - n, best_weights[2].shape[1])), best_weights[3]]\n",
    "\n",
    "j = 0\n",
    "for i in range(len(best_weights[1])):\n",
    "    if i not in nodes_removed:\n",
    "        new_weights[0][:, j] = best_weights[0][:, i]\n",
    "        new_weights[1][j] = best_weights[1][i]\n",
    "        new_weights[2][j, :] = best_weights[2][i, :]\n",
    "        j = j + 1\n",
    "    \n",
    "new_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128 - n, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "new_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "new_model.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shrink_model(model, shrinkage_factor, x_train, y_train, size, to_test, v=0, remove='positive'):\n",
    "    \n",
    "    n = shrinkage_factor\n",
    "    loss, acc = model.evaluate(x_train, y_train, verbose=2)\n",
    "    old = model.get_weights()\n",
    "    best_weights, _, nodes_removed = remove_random_nodes(acc, loss, old, n, to_test, x_train, y_train, v, remove)\n",
    "\n",
    "    if nodes_removed.size:\n",
    "        new_weights = [np.zeros((best_weights[0].shape[0], best_weights[0].shape[1] - n)), np.zeros((best_weights[1].shape[0] - n)), np.zeros((best_weights[2].shape[0] - n, best_weights[2].shape[1])), best_weights[3]]\n",
    "\n",
    "        j = 0\n",
    "        for i in range(len(best_weights[1])):\n",
    "            if i not in nodes_removed:\n",
    "                new_weights[0][:, j] = best_weights[0][:, i]\n",
    "                new_weights[1][j] = best_weights[1][i]\n",
    "                new_weights[2][j, :] = best_weights[2][i, :]\n",
    "                j = j + 1\n",
    "\n",
    "        new_model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(size - n, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(10, activation='softmax')\n",
    "        ])\n",
    "    else:\n",
    "        print(\"Shrinking unsuccessful\")\n",
    "        return model, size\n",
    "    \n",
    "    new_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    new_model.set_weights(new_weights)\n",
    "    print(\"Shrinking successful\")\n",
    "    return new_model, size-n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "313/313 - 0s - loss: 0.0752 - accuracy: 0.9791\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[0.07517477869987488, 0.9790999889373779]"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "new_model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/3\n1875/1875 [==============================] - 3s 2ms/step - loss: 0.0603 - accuracy: 0.9794\nEpoch 2/3\n1875/1875 [==============================] - 3s 2ms/step - loss: 0.0494 - accuracy: 0.9820\nEpoch 3/3\n1875/1875 [==============================] - 3s 2ms/step - loss: 0.0471 - accuracy: 0.9834\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x14222833208>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "new_model.fit(x_train, y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "313/313 - 1s - loss: 0.0702 - accuracy: 0.9811\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[0.07021047919988632, 0.9811000227928162]"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "new_model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3000 - accuracy: 0.9121\n1875/1875 - 2s - loss: 0.1373 - accuracy: 0.9606\n100%|██████████| 25/25 [00:34<00:00,  1.38s/it]Shrinking unsuccessful\n128\n   1/1875 [..............................] - ETA: 0s - loss: 0.0555 - accuracy: 1.0000\n1875/1875 [==============================] - 3s 2ms/step - loss: 0.1481 - accuracy: 0.9553\n1875/1875 - 2s - loss: 0.0886 - accuracy: 0.9737\n100%|██████████| 25/25 [00:38<00:00,  1.56s/it]Shrinking unsuccessful\n128\n  23/1875 [..............................] - ETA: 4s - loss: 0.1120 - accuracy: 0.9592\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.1129 - accuracy: 0.9656\n1875/1875 - 3s - loss: 0.0639 - accuracy: 0.9809\n100%|██████████| 25/25 [00:41<00:00,  1.68s/it]Shrinking unsuccessful\n128\n   1/1875 [..............................] - ETA: 0s - loss: 0.0354 - accuracy: 1.0000\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0931 - accuracy: 0.9707\n1875/1875 - 3s - loss: 0.0495 - accuracy: 0.9852\n100%|██████████| 25/25 [00:41<00:00,  1.66s/it]\nShrinking successful\n126\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0818 - accuracy: 0.9743\n313/313 - 1s - loss: 0.0791 - accuracy: 0.9760\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[0.07908758521080017, 0.9760000109672546]"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "size = 128\n",
    "to_test = 25\n",
    "for _ in range(4):\n",
    "    model.fit(x_train, y_train, epochs=1)\n",
    "    model, size = shrink_model(model, 2, x_train, y_train, size, to_test)\n",
    "    print(len(model.get_weights()[1]))\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/7\n1875/1875 [==============================] - 3s 2ms/step - loss: 2.9835 - accuracy: 0.5638\nEpoch 2/7\n1875/1875 [==============================] - 3s 2ms/step - loss: 1.0273 - accuracy: 0.6250\nEpoch 3/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.9122 - accuracy: 0.6505\nEpoch 4/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.9081 - accuracy: 0.6491\nEpoch 5/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.8583 - accuracy: 0.6604\nEpoch 6/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.8286 - accuracy: 0.6720\nEpoch 7/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.8252 - accuracy: 0.6768\n313/313 - 1s - loss: 0.7109 - accuracy: 0.7263\n#############################\nStarting to shrinking the model by 1\n1875/1875 [==============================] - 3s 2ms/step - loss: 2.8675 - accuracy: 0.5806\n1875/1875 - 3s - loss: 0.9150 - accuracy: 0.6769\n100%|██████████| 15/15 [00:21<00:00,  1.44s/it]\nShrinking successful\n1875/1875 [==============================] - 4s 2ms/step - loss: 1.0527 - accuracy: 0.6182\n1875/1875 - 3s - loss: 0.8130 - accuracy: 0.7088\n100%|██████████| 15/15 [00:21<00:00,  1.46s/it]\nShrinking successful\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.9431 - accuracy: 0.6504\n1875/1875 - 3s - loss: 0.7454 - accuracy: 0.7186\n100%|██████████| 15/15 [00:21<00:00,  1.44s/it]\nShrinking successful\n1875/1875 [==============================] - 3s 2ms/step - loss: 0.9622 - accuracy: 0.6424\n1875/1875 - 3s - loss: 0.8156 - accuracy: 0.6863\n100%|██████████| 15/15 [00:21<00:00,  1.45s/it]\nShrinking successful\n1875/1875 [==============================] - 3s 2ms/step - loss: 0.9474 - accuracy: 0.6425\n1875/1875 - 3s - loss: 0.7891 - accuracy: 0.7043\n100%|██████████| 15/15 [00:21<00:00,  1.46s/it]\nShrinking successful\n1875/1875 [==============================] - 3s 2ms/step - loss: 0.8967 - accuracy: 0.6606\n1875/1875 - 3s - loss: 0.6698 - accuracy: 0.7365\n100%|██████████| 15/15 [00:21<00:00,  1.45s/it]\nShrinking successful\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.8955 - accuracy: 0.6636\n313/313 - 1s - loss: 0.8044 - accuracy: 0.7213\n#############################\nStarting to shrinking the model by 2\n1875/1875 [==============================] - 4s 2ms/step - loss: 2.9213 - accuracy: 0.5738\n1875/1875 - 3s - loss: 0.8267 - accuracy: 0.6643\n100%|██████████| 15/15 [00:23<00:00,  1.58s/it]\nShrinking successful\n1875/1875 [==============================] - 4s 2ms/step - loss: 1.0375 - accuracy: 0.6142\n1875/1875 - 3s - loss: 0.7256 - accuracy: 0.7123\n100%|██████████| 15/15 [00:21<00:00,  1.47s/it]\nShrinking successful\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.9495 - accuracy: 0.6525\n1875/1875 - 3s - loss: 0.7673 - accuracy: 0.7314\n100%|██████████| 15/15 [00:22<00:00,  1.52s/it]\nShrinking successful\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.8958 - accuracy: 0.6743\n1875/1875 - 3s - loss: 0.7344 - accuracy: 0.7454\n100%|██████████| 15/15 [00:21<00:00,  1.45s/it]\nShrinking successful\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.8953 - accuracy: 0.6780\n1875/1875 - 3s - loss: 0.7252 - accuracy: 0.7490\n100%|██████████| 15/15 [00:21<00:00,  1.46s/it]\nShrinking successful\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.9190 - accuracy: 0.6616\n1875/1875 - 3s - loss: 0.8655 - accuracy: 0.6731\n100%|██████████| 15/15 [00:22<00:00,  1.52s/it]\nShrinking successful\n1875/1875 [==============================] - 3s 2ms/step - loss: 0.9251 - accuracy: 0.6568\n313/313 - 1s - loss: 0.8015 - accuracy: 0.7307\n#############################\nStarting to shrinking the model by 3\n1875/1875 [==============================] - 4s 2ms/step - loss: 3.1311 - accuracy: 0.5781\n1875/1875 - 3s - loss: 0.8920 - accuracy: 0.6674\n100%|██████████| 15/15 [00:23<00:00,  1.58s/it]\nShrinking successful\n1875/1875 [==============================] - 4s 2ms/step - loss: 1.0755 - accuracy: 0.6184\n1875/1875 - 3s - loss: 0.7913 - accuracy: 0.6877\n100%|██████████| 15/15 [00:23<00:00,  1.54s/it]\nShrinking successful\n1875/1875 [==============================] - 4s 2ms/step - loss: 1.0096 - accuracy: 0.6228\n1875/1875 - 3s - loss: 0.9082 - accuracy: 0.6816\n100%|██████████| 15/15 [00:19<00:00,  1.30s/it]\nShrinking successful\n1875/1875 [==============================] - 3s 1ms/step - loss: 0.9567 - accuracy: 0.6417\n1875/1875 - 2s - loss: 0.7352 - accuracy: 0.6980\n100%|██████████| 15/15 [00:17<00:00,  1.14s/it]\nShrinking successful\n1875/1875 [==============================] - 3s 1ms/step - loss: 0.9069 - accuracy: 0.6536\n1875/1875 - 2s - loss: 0.7296 - accuracy: 0.7157\n100%|██████████| 15/15 [00:17<00:00,  1.15s/it]\nShrinking successful\n1875/1875 [==============================] - 3s 1ms/step - loss: 0.9029 - accuracy: 0.6621\n1875/1875 - 2s - loss: 0.6708 - accuracy: 0.7268\n100%|██████████| 15/15 [00:17<00:00,  1.14s/it]\nShrinking successful\n1875/1875 [==============================] - 3s 1ms/step - loss: 0.9008 - accuracy: 0.6594\n313/313 - 0s - loss: 0.7943 - accuracy: 0.7063\n#############################\nStarting to shrinking the model by 4\n1875/1875 [==============================] - 3s 1ms/step - loss: 2.8237 - accuracy: 0.5585\n1875/1875 - 2s - loss: 0.8837 - accuracy: 0.6855\n100%|██████████| 15/15 [00:17<00:00,  1.14s/it]\nShrinking successful\n1875/1875 [==============================] - 3s 1ms/step - loss: 1.1146 - accuracy: 0.5942\n1875/1875 - 2s - loss: 0.8558 - accuracy: 0.6794\n100%|██████████| 15/15 [00:17<00:00,  1.15s/it]\nShrinking successful\n1875/1875 [==============================] - 3s 1ms/step - loss: 1.0103 - accuracy: 0.6140\n1875/1875 - 2s - loss: 0.8491 - accuracy: 0.6665\n100%|██████████| 15/15 [00:17<00:00,  1.14s/it]\nShrinking successful\n1875/1875 [==============================] - 3s 1ms/step - loss: 1.0047 - accuracy: 0.6207\n1875/1875 - 2s - loss: 0.8378 - accuracy: 0.6876\n100%|██████████| 15/15 [00:18<00:00,  1.24s/it]\nShrinking successful\n1875/1875 [==============================] - 3s 1ms/step - loss: 1.0066 - accuracy: 0.6261\n1875/1875 - 2s - loss: 0.7937 - accuracy: 0.7150\n100%|██████████| 15/15 [00:17<00:00,  1.15s/it]\nShrinking successful\n1875/1875 [==============================] - 3s 1ms/step - loss: 0.9654 - accuracy: 0.6360\n1875/1875 - 2s - loss: 0.7652 - accuracy: 0.6878\n100%|██████████| 15/15 [00:17<00:00,  1.19s/it]\nShrinking successful\n1875/1875 [==============================] - 3s 2ms/step - loss: 0.9396 - accuracy: 0.6420\n313/313 - 0s - loss: 0.7580 - accuracy: 0.7104\n#############################\nStarting to shrinking the model by 5\n1875/1875 [==============================] - 3s 2ms/step - loss: 2.8477 - accuracy: 0.5723\n1875/1875 - 2s - loss: 0.8517 - accuracy: 0.6982\n100%|██████████| 15/15 [00:17<00:00,  1.16s/it]\nShrinking successful\n1875/1875 [==============================] - 3s 2ms/step - loss: 1.0361 - accuracy: 0.6313\n1875/1875 - 2s - loss: 0.8600 - accuracy: 0.7426\n100%|██████████| 15/15 [00:18<00:00,  1.24s/it]\nShrinking successful\n1875/1875 [==============================] - 3s 1ms/step - loss: 0.9029 - accuracy: 0.6748\n1875/1875 - 2s - loss: 0.6204 - accuracy: 0.7776\n100%|██████████| 15/15 [00:20<00:00,  1.36s/it]\nShrinking successful\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.9093 - accuracy: 0.6744\n1875/1875 - 3s - loss: 0.7048 - accuracy: 0.7216\n100%|██████████| 15/15 [00:21<00:00,  1.44s/it]\nShrinking successful\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.8608 - accuracy: 0.6899\n1875/1875 - 3s - loss: 0.6302 - accuracy: 0.7737\n100%|██████████| 15/15 [00:22<00:00,  1.48s/it]\nShrinking successful\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.8657 - accuracy: 0.6829\n1875/1875 - 3s - loss: 0.6035 - accuracy: 0.7784\n100%|██████████| 15/15 [00:22<00:00,  1.48s/it]\nShrinking successful\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.9021 - accuracy: 0.6631\n313/313 - 1s - loss: 0.7452 - accuracy: 0.7310\n#############################\n"
    }
   ],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "rep = 6\n",
    "\n",
    "best_models = []\n",
    "sizes = []\n",
    "scores = []\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "start_weights = copy.deepcopy(model.get_weights())\n",
    "model.fit(x_train, y_train, epochs=7)\n",
    "loss, acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"#############################\")\n",
    "best_models += [model]\n",
    "scores += [(loss, acc)]\n",
    "sizes +=[128]\n",
    "for i in range(1, 6):\n",
    "    print(f\"Starting to shrinking the model by {i}\")\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.set_weights(start_weights)\n",
    "    size = 128\n",
    "    to_test = 15\n",
    "    for _ in range(rep):\n",
    "        model.fit(x_train, y_train, epochs=1)\n",
    "        model, size = shrink_model(model, i, x_train, y_train, size, to_test, remove='always')\n",
    "    model.fit(x_train, y_train, epochs=1)\n",
    "    loss, acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "    print(\"#############################\")\n",
    "    best_models += [model]\n",
    "    scores += [(loss, acc)]\n",
    "    sizes +=[(len(model.get_weights()[1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[(0.7108903527259827, 0.7263000011444092), (0.8043630123138428, 0.7213000059127808), (0.8015145659446716, 0.7307000160217285), (0.7943050861358643, 0.7063000202178955), (0.7579924464225769, 0.7103999853134155), (0.7451807856559753, 0.7310000061988831)]\n[128, 122, 116, 110, 104, 98]\n"
    }
   ],
   "source": [
    "print(scores)\n",
    "sizes = [128, 122, 116, 110, 104, 98]\n",
    "print(sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Starting plain train of Dense size 122\nEpoch 1/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 2.6516 - accuracy: 0.5721\nEpoch 2/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.9663 - accuracy: 0.6399\nEpoch 3/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.9084 - accuracy: 0.6562\nEpoch 4/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.9136 - accuracy: 0.6532\nEpoch 5/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.8527 - accuracy: 0.6733\nEpoch 6/7\n1875/1875 [==============================] - 3s 2ms/step - loss: 0.8295 - accuracy: 0.6766\nEpoch 7/7\n1875/1875 [==============================] - 3s 2ms/step - loss: 0.8061 - accuracy: 0.6867\n313/313 - 1s - loss: 0.6853 - accuracy: 0.7212\n###############################\nStarting plain train of Dense size 116\nEpoch 1/7\n1875/1875 [==============================] - 3s 2ms/step - loss: 2.3015 - accuracy: 0.5609\nEpoch 2/7\n1875/1875 [==============================] - 3s 2ms/step - loss: 0.9510 - accuracy: 0.6330\nEpoch 3/7\n1875/1875 [==============================] - 3s 2ms/step - loss: 0.8687 - accuracy: 0.6665\nEpoch 4/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.8348 - accuracy: 0.6827\nEpoch 5/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.8134 - accuracy: 0.6912\nEpoch 6/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.7813 - accuracy: 0.7034\nEpoch 7/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.7947 - accuracy: 0.6990\n313/313 - 1s - loss: 0.6190 - accuracy: 0.7529\n###############################\nStarting plain train of Dense size 110\nEpoch 1/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 2.1849 - accuracy: 0.5991\nEpoch 2/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.8928 - accuracy: 0.6678\nEpoch 3/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.8491 - accuracy: 0.6891\nEpoch 4/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.8437 - accuracy: 0.6983\nEpoch 5/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.8491 - accuracy: 0.6957\nEpoch 6/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.7884 - accuracy: 0.7278\nEpoch 7/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.7657 - accuracy: 0.7377\n313/313 - 1s - loss: 0.6548 - accuracy: 0.7940\n###############################\nStarting plain train of Dense size 104\nEpoch 1/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 2.5995 - accuracy: 0.5498\nEpoch 2/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 1.0211 - accuracy: 0.6213\nEpoch 3/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.9198 - accuracy: 0.6492\nEpoch 4/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.8836 - accuracy: 0.6594\nEpoch 5/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.8663 - accuracy: 0.6625\nEpoch 6/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.8420 - accuracy: 0.6734\nEpoch 7/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.8088 - accuracy: 0.6830\n313/313 - 1s - loss: 0.7335 - accuracy: 0.7152\n###############################\nStarting plain train of Dense size 98\nEpoch 1/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 2.2115 - accuracy: 0.5524\nEpoch 2/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 1.0148 - accuracy: 0.6191\nEpoch 3/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.9460 - accuracy: 0.6380\nEpoch 4/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.9105 - accuracy: 0.6495\nEpoch 5/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.8642 - accuracy: 0.6638\nEpoch 6/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.8764 - accuracy: 0.6649\nEpoch 7/7\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.8664 - accuracy: 0.6646\n313/313 - 1s - loss: 0.7266 - accuracy: 0.7025\n###############################\n"
    }
   ],
   "source": [
    "scores_plain = [scores[0]]\n",
    "for i in range(1, len(scores)):\n",
    "    print(f\"Starting plain train of Dense size {sizes[i]}\")\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(sizes[i], activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, epochs=7)\n",
    "    loss, acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "    scores_plain += [(loss, acc)]\n",
    "    print(\"###############################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Starting to shrinking the model by 1\n1875/1875 [==============================] - 3s 1ms/step - loss: 3.1455 - accuracy: 0.5739\n1875/1875 - 2s - loss: 0.7596 - accuracy: 0.6959\n100%|██████████| 15/15 [00:16<00:00,  1.08s/it]\nShrinking successful\n1875/1875 [==============================] - 2s 1ms/step - loss: 1.0185 - accuracy: 0.6220\n1875/1875 - 2s - loss: 0.7235 - accuracy: 0.7375\n100%|██████████| 15/15 [00:16<00:00,  1.08s/it]\nShrinking successful\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.9128 - accuracy: 0.6544\n1875/1875 - 2s - loss: 0.6841 - accuracy: 0.7268\n100%|██████████| 15/15 [00:16<00:00,  1.09s/it]Shrinking unsuccessful\n  69/1875 [>.............................] - ETA: 2s - loss: 0.8521 - accuracy: 0.6775\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.8814 - accuracy: 0.6667\n1875/1875 - 2s - loss: 0.6386 - accuracy: 0.7567\n100%|██████████| 15/15 [00:16<00:00,  1.11s/it]Shrinking unsuccessful\n  78/1875 [>.............................] - ETA: 2s - loss: 0.9236 - accuracy: 0.6546\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.8917 - accuracy: 0.6567\n1875/1875 - 2s - loss: 0.6381 - accuracy: 0.7627\n100%|██████████| 15/15 [00:16<00:00,  1.11s/it]Shrinking unsuccessful\n  74/1875 [>.............................] - ETA: 2s - loss: 0.8618 - accuracy: 0.6698\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.8595 - accuracy: 0.6697\n1875/1875 - 2s - loss: 0.6296 - accuracy: 0.7604\n100%|██████████| 15/15 [00:16<00:00,  1.12s/it]\nShrinking successful\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.8287 - accuracy: 0.6860\n313/313 - 0s - loss: 0.6749 - accuracy: 0.7603\n#############################\nStarting to shrinking the model by 2\n1875/1875 [==============================] - 2s 1ms/step - loss: 2.8638 - accuracy: 0.5707\n1875/1875 - 2s - loss: 0.8151 - accuracy: 0.6963\n100%|██████████| 15/15 [00:16<00:00,  1.11s/it]\nShrinking successful\n1875/1875 [==============================] - 2s 1ms/step - loss: 1.0155 - accuracy: 0.6174\n1875/1875 - 2s - loss: 0.7589 - accuracy: 0.7279\n100%|██████████| 15/15 [00:16<00:00,  1.12s/it]Shrinking unsuccessful\n  74/1875 [>.............................] - ETA: 2s - loss: 0.8866 - accuracy: 0.6562\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.8872 - accuracy: 0.6617\n1875/1875 - 2s - loss: 0.6369 - accuracy: 0.7569\n100%|██████████| 15/15 [00:16<00:00,  1.13s/it]\nShrinking successful\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.8544 - accuracy: 0.6760\n1875/1875 - 2s - loss: 0.7106 - accuracy: 0.7281\n100%|██████████| 15/15 [00:16<00:00,  1.12s/it]Shrinking unsuccessful\n  73/1875 [>.............................] - ETA: 2s - loss: 0.8474 - accuracy: 0.6725\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.8385 - accuracy: 0.6865\n1875/1875 - 2s - loss: 0.6308 - accuracy: 0.7751\n100%|██████████| 15/15 [00:16<00:00,  1.12s/it]\nShrinking successful\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.8648 - accuracy: 0.6876\n1875/1875 - 2s - loss: 0.6480 - accuracy: 0.7634\n100%|██████████| 15/15 [00:16<00:00,  1.13s/it]\nShrinking successful\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.8562 - accuracy: 0.6885\n313/313 - 0s - loss: 0.9152 - accuracy: 0.6844\n#############################\nStarting to shrinking the model by 3\n1875/1875 [==============================] - 2s 1ms/step - loss: 2.7290 - accuracy: 0.5630\n1875/1875 - 2s - loss: 0.9121 - accuracy: 0.6812\n100%|██████████| 15/15 [00:17<00:00,  1.15s/it]\nShrinking successful\n1875/1875 [==============================] - 2s 1ms/step - loss: 1.0422 - accuracy: 0.6200\n1875/1875 - 2s - loss: 0.7824 - accuracy: 0.7085\n100%|██████████| 15/15 [00:17<00:00,  1.15s/it]Shrinking unsuccessful\n  68/1875 [>.............................] - ETA: 2s - loss: 0.8596 - accuracy: 0.6719\n1875/1875 [==============================] - 3s 1ms/step - loss: 0.9128 - accuracy: 0.6532\n1875/1875 - 2s - loss: 0.6931 - accuracy: 0.7133\n100%|██████████| 15/15 [00:16<00:00,  1.12s/it]\nShrinking successful\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.8718 - accuracy: 0.6674\n1875/1875 - 2s - loss: 0.7047 - accuracy: 0.7273\n100%|██████████| 15/15 [00:17<00:00,  1.14s/it]\nShrinking successful\n1875/1875 [==============================] - 3s 1ms/step - loss: 0.8766 - accuracy: 0.6671\n1875/1875 - 2s - loss: 0.8394 - accuracy: 0.6409\n100%|██████████| 15/15 [00:16<00:00,  1.12s/it]Shrinking unsuccessful\n  68/1875 [>.............................] - ETA: 2s - loss: 0.9470 - accuracy: 0.6273\n1875/1875 [==============================] - 3s 1ms/step - loss: 0.9271 - accuracy: 0.6464\n1875/1875 - 2s - loss: 0.6715 - accuracy: 0.7398\n100%|██████████| 15/15 [00:17<00:00,  1.15s/it]\nShrinking successful\n1875/1875 [==============================] - 3s 1ms/step - loss: 0.8750 - accuracy: 0.6698\n313/313 - 0s - loss: 0.7284 - accuracy: 0.7295\n#############################\nStarting to shrinking the model by 4\n1875/1875 [==============================] - 3s 1ms/step - loss: 2.6912 - accuracy: 0.5710\n1875/1875 - 2s - loss: 0.9302 - accuracy: 0.6665\n100%|██████████| 15/15 [00:16<00:00,  1.12s/it]\nShrinking successful\n1875/1875 [==============================] - 3s 1ms/step - loss: 1.1289 - accuracy: 0.5945\n1875/1875 - 2s - loss: 0.7886 - accuracy: 0.6921\n100%|██████████| 15/15 [00:16<00:00,  1.13s/it]Shrinking unsuccessful\n  72/1875 [>.............................] - ETA: 2s - loss: 0.9734 - accuracy: 0.6285\n1875/1875 [==============================] - 3s 1ms/step - loss: 0.9592 - accuracy: 0.6333\n1875/1875 - 2s - loss: 0.7092 - accuracy: 0.7236\n100%|██████████| 15/15 [00:16<00:00,  1.12s/it]\nShrinking successful\n1875/1875 [==============================] - 3s 1ms/step - loss: 0.9431 - accuracy: 0.6436\n1875/1875 - 2s - loss: 0.7252 - accuracy: 0.7178\n100%|██████████| 15/15 [00:16<00:00,  1.13s/it]\nShrinking successful\n1875/1875 [==============================] - 3s 1ms/step - loss: 0.9387 - accuracy: 0.6471\n1875/1875 - 2s - loss: 0.6925 - accuracy: 0.7334\n100%|██████████| 15/15 [00:17<00:00,  1.13s/it]Shrinking unsuccessful\n  35/1875 [..............................] - ETA: 2s - loss: 0.9794 - accuracy: 0.6652\n1875/1875 [==============================] - 3s 1ms/step - loss: 0.9118 - accuracy: 0.6539\n1875/1875 - 2s - loss: 0.6976 - accuracy: 0.7300\n100%|██████████| 15/15 [00:17<00:00,  1.14s/it]Shrinking unsuccessful\n  76/1875 [>.............................] - ETA: 2s - loss: 0.8270 - accuracy: 0.6871\n1875/1875 [==============================] - 3s 1ms/step - loss: 0.8758 - accuracy: 0.6647\n313/313 - 0s - loss: 0.7143 - accuracy: 0.7226\n#############################\nStarting to shrinking the model by 5\n1875/1875 [==============================] - 3s 1ms/step - loss: 2.6819 - accuracy: 0.5894\n1875/1875 - 2s - loss: 0.9417 - accuracy: 0.6834\n100%|██████████| 15/15 [00:17<00:00,  1.14s/it]\nShrinking successful\n1875/1875 [==============================] - 3s 1ms/step - loss: 0.9768 - accuracy: 0.6439\n1875/1875 - 2s - loss: 0.8017 - accuracy: 0.7575\n100%|██████████| 15/15 [00:17<00:00,  1.16s/it]\nShrinking successful\n1875/1875 [==============================] - 3s 1ms/step - loss: 0.8985 - accuracy: 0.6773\n1875/1875 - 2s - loss: 0.6466 - accuracy: 0.7710\n100%|██████████| 15/15 [00:16<00:00,  1.11s/it]Shrinking unsuccessful\n  76/1875 [>.............................] - ETA: 2s - loss: 1.0106 - accuracy: 0.6447\n1875/1875 [==============================] - 3s 1ms/step - loss: 0.8381 - accuracy: 0.6933\n1875/1875 - 2s - loss: 0.6197 - accuracy: 0.7822\n100%|██████████| 15/15 [00:16<00:00,  1.12s/it]Shrinking unsuccessful\n  76/1875 [>.............................] - ETA: 2s - loss: 0.8157 - accuracy: 0.7109\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.7976 - accuracy: 0.7063\n1875/1875 - 2s - loss: 0.5974 - accuracy: 0.7808\n100%|██████████| 15/15 [00:16<00:00,  1.12s/it]Shrinking unsuccessful\n 124/1875 [>.............................] - ETA: 2s - loss: 0.7543 - accuracy: 0.7200\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.7924 - accuracy: 0.7100\n1875/1875 - 2s - loss: 0.5631 - accuracy: 0.7738\n100%|██████████| 15/15 [00:16<00:00,  1.11s/it]Shrinking unsuccessful\n  36/1875 [..............................] - ETA: 2s - loss: 0.8672 - accuracy: 0.6849\n1875/1875 [==============================] - 3s 1ms/step - loss: 0.8427 - accuracy: 0.6904\n313/313 - 0s - loss: 0.6719 - accuracy: 0.7557\n#############################\n"
    }
   ],
   "source": [
    "best_models_p = []\n",
    "sizes_p = []\n",
    "scores_p = []\n",
    "best_models_p += [model]\n",
    "scores_p += [(loss, acc)]\n",
    "sizes_p +=[128]\n",
    "for i in range(1, 6):\n",
    "    print(f\"Starting to shrinking the model by {i}\")\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.set_weights(start_weights)\n",
    "    size = 128\n",
    "    to_test = 15\n",
    "    for _ in range(rep):\n",
    "        model.fit(x_train, y_train, epochs=1)\n",
    "        model, size = shrink_model(model, i, x_train, y_train, size, to_test, remove='positive')\n",
    "    model.fit(x_train, y_train, epochs=1)\n",
    "    loss, acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "    print(\"#############################\")\n",
    "    best_models += [model]\n",
    "    scores_p += [(loss, acc)]\n",
    "    sizes_p +=[(len(model.get_weights()[1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[128, 125, 120, 116, 116, 118]\n"
    }
   ],
   "source": [
    "print(sizes_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[(0.7108903527259827, 0.7263000011444092), (0.8043630123138428, 0.7213000059127808), (0.8015145659446716, 0.7307000160217285), (0.7943050861358643, 0.7063000202178955), (0.7579924464225769, 0.7103999853134155), (0.7451807856559753, 0.7310000061988831)]\n#############################\n[(0.7179182767868042, 0.7250000238418579), (0.6748734712600708, 0.7602999806404114), (0.9151998162269592, 0.6844000220298767), (0.7284160852432251, 0.7294999957084656), (0.7142876982688904, 0.722599983215332), (0.6719245910644531, 0.7556999921798706)]\n#############################\n[(0.7108903527259827, 0.7263000011444092), (0.6853137016296387, 0.7211999893188477), (0.6189708113670349, 0.7529000043869019), (0.6547967195510864, 0.7940000295639038), (0.7334647178649902, 0.7152000069618225), (0.726564884185791, 0.7024999856948853)]\n"
    }
   ],
   "source": [
    "print(scores)\n",
    "print(\"#############################\")\n",
    "print(scores_p)\n",
    "print(\"#############################\")\n",
    "print(scores_plain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(scores)):\n",
    "    print(\"Loss change:\", (scores_plain[i][0] - scores[i][0])/scores_plain[i][0] *100, \"--- Acc change:\", -(scores_plain[i][1] - scores[i][1]) / scores_plain[i][1] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove_list = np.arange(1, 65)\n",
    "num_rep = 100\n",
    "loss_diff = np.zeros(num_rep)\n",
    "acc_diff = np.zeros(num_rep)\n",
    "loss_change = np.zeros(num_rep)\n",
    "acc_change = np.zeros(num_rep)\n",
    "nodes_removed_list = []\n",
    "num_nodes_removed = np.zeros(num_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(to_remove_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_rep):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, epochs=10)\n",
    "    loss, acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "    \n",
    "    n = np.random.choice(to_remove_list, 1)\n",
    "    \n",
    "    best_weights, _, nodes_removed = remove_nodes(acc, loss, model.get_weights(), n, 1, x_train, y_train, 0)\n",
    "    \n",
    "    model.set_weights(best_weights)\n",
    "    print(n)\n",
    "    \n",
    "    loss_new, acc_new = model.evaluate(x_test, y_test, verbose=2)\n",
    "    \n",
    "    loss_diff[i] = loss - loss_new\n",
    "    acc_diff[i] = acc_new - acc\n",
    "    loss_change[i] = loss_diff[i] / loss * 100\n",
    "    acc_change[i] = acc_diff[i] / acc * 100\n",
    "    num_nodes_removed[i] = n\n",
    "    nodes_removed_list += [nodes_removed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 65):\n",
    "    print(f\"{i} nodes removed\")\n",
    "    print(\"Loss changes:\",loss_change[num_nodes_removed == i])\n",
    "    print(\"Accuracy changes:\",acc_change[num_nodes_removed == i])\n",
    "    print(\"#########################\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitmastercondad556aba890334ca2b025f74f5b164268",
   "display_name": "Python 3.7.6 64-bit ('master': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}